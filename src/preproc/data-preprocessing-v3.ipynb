{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13044847,"sourceType":"datasetVersion","datasetId":8260282}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"2749441d","cell_type":"markdown","source":"\n# Thesis Chapters 4–5 — Data Processing Notebook\n**Datasets**: MultiHateClip, HateMM, HateClipSeg  \n**Environment**: Kaggle\n\nThis notebook standardizes the three datasets into CSV manifests that point to the **actual video paths** on Kaggle.\n\n**Input root (read-only):** `/kaggle/input/dataset-sample`  \n**Output root (writable):** `/kaggle/working/processed`\n\n> Comments are in English as requested.\n","metadata":{}},{"id":"201d9dcd","cell_type":"code","source":"\n# === Imports & Global Paths ===\nfrom pathlib import Path\nimport pandas as pd\n\n# Kaggle dataset root (read-only)\nDATASET_ROOT = Path(\"/kaggle/input/dataset-sample/preprocess_lab/data/raw\")\n\n# Output directory for processed manifests (writable on Kaggle)\nOUT_DIR = Path(\"/kaggle/working/processed\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"Input root:\", DATASET_ROOT)\nprint(\"Output root:\", OUT_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T02:36:08.875179Z","iopub.execute_input":"2025-09-17T02:36:08.875492Z","iopub.status.idle":"2025-09-17T02:36:08.882127Z","shell.execute_reply.started":"2025-09-17T02:36:08.875443Z","shell.execute_reply":"2025-09-17T02:36:08.881340Z"}},"outputs":[{"name":"stdout","text":"Input root: /kaggle/input/dataset-sample/preprocess_lab/data/raw\nOutput root: /kaggle/working/processed\n","output_type":"stream"}],"execution_count":3},{"id":"47235e14","cell_type":"markdown","source":"## 1) MultiHateClip — Load annotations and map to local video files","metadata":{}},{"id":"c8465d37","cell_type":"code","source":"\n# MultiHateClip folder and expected files\nmh_root = DATASET_ROOT / \"MultiHateClip\"\n\n# Read splits (TSV format)\nmh_train = pd.read_csv(mh_root / \"train.tsv\", sep=\"\\t\")\nmh_valid = pd.read_csv(mh_root / \"valid.tsv\", sep=\"\\t\")\nmh_test  = pd.read_csv(mh_root / \"test.tsv\",  sep=\"\\t\")\n\n# Concatenate and add a 'split' column\ndf_mh = pd.concat([mh_train, mh_valid, mh_test], keys=[\"train\",\"valid\",\"test\"], names=[\"split\"])\ndf_mh.reset_index(level=0, inplace=True)\ndf_mh.rename(columns={\"level_0\": \"split\"}, inplace=True)\n\n# Map each row to its actual .mp4 path under /data/{split}/\ndef mh_path(row):\n    split = row[\"split\"]\n    # Some versions use 'video_id' column; fallback to first column if missing\n    vid = row[\"video_id\"] if \"video_id\" in row else row.iloc[0]\n    return str(mh_root / \"data\" / split / f\"{vid}.mp4\")\n\ndf_mh[\"video_path\"] = df_mh.apply(mh_path, axis=1)\ndf_mh[\"dataset\"] = \"MultiHateClip\"\n\nprint(\"MultiHateClip rows:\", len(df_mh))\ndf_mh.head(3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T02:36:11.348940Z","iopub.execute_input":"2025-09-17T02:36:11.349253Z","iopub.status.idle":"2025-09-17T02:36:11.486063Z","shell.execute_reply.started":"2025-09-17T02:36:11.349225Z","shell.execute_reply":"2025-09-17T02:36:11.484830Z"}},"outputs":[{"name":"stdout","text":"MultiHateClip rows: 1001\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   split     Video_ID Majority_Voting                            Label  \\\n0  train  4V0KGql_fUI          Normal             ['Normal', 'Normal']   \n1  train  5snzFreG79c       Offensive       ['Offensive', 'Offensive']   \n2  train  EyE82W10wgk          Normal  ['Normal', 'Counter Narrative']   \n\n  Target_Victim                            Component    Duration  \\\n0            []                                   []          []   \n1    ['Couple']  ['Transcript', 'Audio', 'Metadata']  [(30, 39)]   \n2            []                                   []          []   \n\n                                          video_path        dataset  \n0  /kaggle/input/dataset-sample/preprocess_lab/da...  MultiHateClip  \n1  /kaggle/input/dataset-sample/preprocess_lab/da...  MultiHateClip  \n2  /kaggle/input/dataset-sample/preprocess_lab/da...  MultiHateClip  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>Video_ID</th>\n      <th>Majority_Voting</th>\n      <th>Label</th>\n      <th>Target_Victim</th>\n      <th>Component</th>\n      <th>Duration</th>\n      <th>video_path</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train</td>\n      <td>4V0KGql_fUI</td>\n      <td>Normal</td>\n      <td>['Normal', 'Normal']</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>MultiHateClip</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train</td>\n      <td>5snzFreG79c</td>\n      <td>Offensive</td>\n      <td>['Offensive', 'Offensive']</td>\n      <td>['Couple']</td>\n      <td>['Transcript', 'Audio', 'Metadata']</td>\n      <td>[(30, 39)]</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>MultiHateClip</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train</td>\n      <td>EyE82W10wgk</td>\n      <td>Normal</td>\n      <td>['Normal', 'Counter Narrative']</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>[]</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>MultiHateClip</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"056e7e02","cell_type":"markdown","source":"## 2) HateMM — Load annotations and map to hate/non-hate folders","metadata":{}},{"id":"ef7e8a78","cell_type":"code","source":"\nhmm_root = DATASET_ROOT / \"HateMM\"\ndf_hmm = pd.read_csv(hmm_root / \"HateMM_annotation.csv\")\n\n# Resolve each video to either hate_videos/ or non_hate_videos/ based on the label\ndef hmm_path(row):\n    sub = \"hate_videos\" if str(row[\"label\"]).strip().lower() == \"hate\" else \"non_hate_videos\"\n    return str(hmm_root / \"data\" / sub / row[\"video_file_name\"])\n\ndf_hmm[\"video_path\"] = df_hmm.apply(hmm_path, axis=1)\ndf_hmm[\"dataset\"] = \"HateMM\"\n\nprint(\"HateMM rows:\", len(df_hmm))\ndf_hmm.head(3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T02:36:17.869258Z","iopub.execute_input":"2025-09-17T02:36:17.869595Z","iopub.status.idle":"2025-09-17T02:36:17.913937Z","shell.execute_reply.started":"2025-09-17T02:36:17.869569Z","shell.execute_reply":"2025-09-17T02:36:17.913113Z"}},"outputs":[{"name":"stdout","text":"HateMM rows: 1083\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        video_file_name     label                hate_snippet  target  \\\n0      hate_video_1.mp4      Hate  [['00:00:34', '00:01:34']]  Blacks   \n1      hate_video_2.mp4      Hate  [['00:00:06', '00:02:06']]  Blacks   \n2  non_hate_video_1.mp4  Non Hate                         NaN  Others   \n\n                                          video_path dataset  \n0  /kaggle/input/dataset-sample/preprocess_lab/da...  HateMM  \n1  /kaggle/input/dataset-sample/preprocess_lab/da...  HateMM  \n2  /kaggle/input/dataset-sample/preprocess_lab/da...  HateMM  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_file_name</th>\n      <th>label</th>\n      <th>hate_snippet</th>\n      <th>target</th>\n      <th>video_path</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hate_video_1.mp4</td>\n      <td>Hate</td>\n      <td>[['00:00:34', '00:01:34']]</td>\n      <td>Blacks</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>HateMM</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hate_video_2.mp4</td>\n      <td>Hate</td>\n      <td>[['00:00:06', '00:02:06']]</td>\n      <td>Blacks</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>HateMM</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>non_hate_video_1.mp4</td>\n      <td>Non Hate</td>\n      <td>NaN</td>\n      <td>Others</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>HateMM</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"id":"a8da5c1b","cell_type":"markdown","source":"## 3) HateClipSeg — Flatten segment-level annotations and map to segment video files","metadata":{}},{"id":"e97fedef","cell_type":"code","source":"\nhcs_root = DATASET_ROOT / \"HateClipSeg\"\ndf_video = pd.read_csv(hcs_root / \"video_level_annotation.csv\")  # kept for reference\ndf_seg   = pd.read_csv(hcs_root / \"segment_level_annotation.csv\")\n\n# Expand segment-level entries: one row per segment with start/end and a label vector\nrecords = []\nfor _, row in df_seg.iterrows():\n    vid = row[\"Video ID\"]\n    # segment-level label is stored as a stringified list-of-lists; same for timestamps\n    labels = eval(row[\"Segment-Level Label\"])\n    times  = eval(row[\"Segment Timestamp\"])\n    for lbl_vec, (t0, t1) in zip(labels, times):\n        records.append({\n            \"Video ID\": vid,\n            \"Segment Labels\": lbl_vec,    # e.g., [0,1,0,0,0,0] (index mapping in the dataset README)\n            \"Start\": t0,\n            \"End\": t1,\n            # Point to segment-level videos if present\n            \"video_path\": str(hcs_root / \"data\" / \"segment_level\" / f\"{vid}.mp4\")\n        })\n\ndf_hcs = pd.DataFrame.from_records(records)\ndf_hcs[\"dataset\"] = \"HateClipSeg\"\n\nprint(\"HateClipSeg rows:\", len(df_hcs))\ndf_hcs.head(3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T02:36:21.236781Z","iopub.execute_input":"2025-09-17T02:36:21.237108Z","iopub.status.idle":"2025-09-17T02:36:21.297841Z","shell.execute_reply.started":"2025-09-17T02:36:21.237082Z","shell.execute_reply":"2025-09-17T02:36:21.296810Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Video ID'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1896798891.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_seg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mvid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Video ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# segment-level label is stored as a stringified list-of-lists; same for timestamps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Segment-Level Label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Video ID'"],"ename":"KeyError","evalue":"'Video ID'","output_type":"error"}],"execution_count":6},{"id":"0eaf4245","cell_type":"markdown","source":"### (Optional) Normalize labels to a canonical set for training convenience","metadata":{}},{"id":"e1a576a6","cell_type":"code","source":"\n# This section provides helper functions to standardize label names across datasets,\n# if you need a unified set like: ['normal','hateful','insulting','sexual','violence','self-harm','offensive'].\n# It is optional and safe to skip for raw manifests.\n\ndef normalize_label_string(x: str) -> str:\n    m = {\n        \"non hate\": \"normal\",\n        \"nonhate\": \"normal\",\n        \"non_hate\": \"normal\",\n        \"non-hate\": \"normal\",\n        \"normal\": \"normal\",\n        \"hate\": \"hateful\",\n        \"hateful\": \"hateful\",\n        \"offensive\": \"offensive\",\n        \"insult\": \"insulting\",\n        \"insulting\": \"insulting\",\n        \"sexual\": \"sexual\",\n        \"violence\": \"violence\",\n        \"violent\": \"violence\",\n        \"harm\": \"self-harm\",\n        \"self-harm\": \"self-harm\",\n        \"self_harm\": \"self-harm\"\n    }\n    k = str(x).strip().lower()\n    return m.get(k, k)\n\n# Example: apply to HateMM (binary) → 'normal' / 'hateful'\nif \"label\" in df_hmm.columns:\n    df_hmm[\"label_canonical\"] = df_hmm[\"label\"].apply(normalize_label_string)\ndf_hmm.head(2)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"dbd6d3a3","cell_type":"markdown","source":"## 4) Save processed manifests to `/kaggle/working/processed`","metadata":{}},{"id":"9a3a829c","cell_type":"code","source":"\n(df_mh\n .to_csv(OUT_DIR / \"multihateclip.csv\", index=False))\n(df_hmm\n .to_csv(OUT_DIR / \"hatemm.csv\", index=False))\n(df_hcs\n .to_csv(OUT_DIR / \"hateclipseg.csv\", index=False))\n\nprint(\"Saved:\")\nprint(\" -\", OUT_DIR / \"multihateclip.csv\")\nprint(\" -\", OUT_DIR / \"hatemm.csv\")\nprint(\" -\", OUT_DIR / \"hateclipseg.csv\")\n","metadata":{},"outputs":[],"execution_count":null},{"id":"a1de5bbf","cell_type":"markdown","source":"## 5) Quick sanity checks","metadata":{}},{"id":"147c2e0f","cell_type":"code","source":"\n# Check existence of a few sample files to ensure paths are correct.\n# (Kaggle inputs can be read; not all files are guaranteed to exist in the sample.)\nfrom pathlib import Path\n\ndef exists(p): \n    try: \n        return Path(p).exists()\n    except Exception:\n        return False\n\nprint(\"Sample MultiHateClip path exists?\",\n      exists(df_mh.loc[df_mh.index[0], \"video_path\"]) if len(df_mh) else None)\n\nprint(\"Sample HateMM path exists?\",\n      exists(df_hmm.loc[df_hmm.index[0], \"video_path\"]) if len(df_hmm) else None)\n\nprint(\"Sample HateClipSeg path exists?\",\n      exists(df_hcs.loc[df_hcs.index[0], \"video_path\"]) if len(df_hcs) else None)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"773bde5d","cell_type":"markdown","source":"\n### Next steps\n- Use these CSVs as input to your Chapter 4 training pipeline (frame/audio extraction, ASR, feature caching).\n- If you need, I can extend this notebook with ffmpeg/OpenCV extractors and a CLIP/BERT/wav2vec2 feature cache.\n","metadata":{}}]}