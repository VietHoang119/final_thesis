{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13100235,"sourceType":"datasetVersion","datasetId":8298257}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Normalization and Description","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport json, ast, re, math, subprocess, shlex\n\n# === Adjust this if your Kaggle dataset slug/path differs ===\nDATASET_ROOT = Path(\"/kaggle/input/thesis-dataset/Thesis_dataset\")\nANN_PATH     = DATASET_ROOT / \"HateMM_annotation.csv\"\n\n# Expected media layout (as you showed): /hate_videos, /non_hate_videos\nMEDIA_ROOT   = DATASET_ROOT\n\nOUT_DIR = Path(\"/kaggle/working/processed\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\n# Canonical label set (unified across your thesis)\nCANON_LABELS = [\"normal\",\"offensive\",\"hateful\",\"insulting\",\"sexual\",\"violence\",\"self-harm\"]\n\nprint(\"Annotation:\", ANN_PATH.exists(), ANN_PATH)\nprint(\"Media root:\", MEDIA_ROOT.exists(), MEDIA_ROOT)\nprint(\"Output dir:\", OUT_DIR)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------- Column utilities ----------\n\ndef _norm_key(s: str) -> str:\n    if not isinstance(s, str): s = str(s)\n    return s.strip().lower().replace(\" \",\"\").replace(\"_\",\"\").replace(\"-\",\"\")\n\ndef find_col(df: pd.DataFrame, *candidates):\n    \"\"\"Return the first matched column (fuzzy) from a list of candidate names.\"\"\"\n    norm_map = {_norm_key(c): c for c in df.columns}\n    for cand in candidates:\n        key = _norm_key(cand)\n        if key in norm_map:\n            return norm_map[key]\n    return None\n\ndef safe_parse_list(x):\n    \"\"\"Parse list-like strings; try JSON, then literal_eval; return [] if fail.\"\"\"\n    if isinstance(x, (list, tuple)): return list(x)\n    if not isinstance(x, str): return []\n    s = x.strip()\n    try:\n        return json.loads(s)\n    except Exception:\n        try:\n            return ast.literal_eval(s)\n        except Exception:\n            return []\n\n# ---------- Label normalization ----------\n\ndef normalize_label_string(x: str) -> str:\n    if x is None: return \"normal\"\n    k = str(x).strip().lower()\n    m = {\n        \"nonhate\":\"normal\", \"non_hate\":\"normal\", \"non-hate\":\"normal\", \"non hate\":\"normal\",\n        \"none\":\"normal\", \"neutral\":\"normal\", \"benign\":\"normal\", \"normal\":\"normal\",\n        \"hate\":\"hateful\", \"hateful\":\"hateful\",\n        \"offensive\":\"offensive\",\n        \"insult\":\"insulting\", \"insulting\":\"insulting\",\n        \"sexual\":\"sexual\",\n        \"violence\":\"violence\", \"violent\":\"violence\",\n        \"selfharm\":\"self-harm\", \"self-harm\":\"self-harm\", \"self_harm\":\"self-harm\", \"harm\":\"self-harm\",\n    }\n    return m.get(k, k)\n\n# ---------- Sample id ----------\n\ndef build_sample_id(dataset, video_id, start, end, label):\n    s = \"0\" if (start is None or pd.isna(start)) else f\"{float(start):.3f}\"\n    e = \"end\" if (end is None or pd.isna(end)) else f\"{float(end):.3f}\"\n    return f\"{dataset}__{video_id}__{s}_{e}__{label}\"\n\n# ---------- Timestamp parsing ----------\n\ndef parse_timestamp_pair(v):\n    \"\"\"\n    Accepts [start, end], or {\"start\":..,\"end\":..}, or strings \"start-end\".\n    Returns (t0, t1) as floats or (None, None) if invalid.\n    \"\"\"\n    if isinstance(v, (list, tuple)) and len(v) >= 2:\n        try: return float(v[0]), float(v[1])\n        except Exception: return (None, None)\n    if isinstance(v, dict) and {\"start\",\"end\"}.issubset({k.lower() for k in v.keys()}):\n        try:\n            return float(v.get(\"start\") or v.get(\"Start\")), float(v.get(\"end\") or v.get(\"End\"))\n        except Exception:\n            return (None, None)\n    if isinstance(v, str):\n        m = re.match(r\"^\\s*([0-9.]+)\\s*[-,:]\\s*([0-9.]+)\\s*$\", v)\n        if m:\n            try: return float(m.group(1)), float(m.group(2))\n            except Exception: return (None, None)\n    return (None, None)\n\n# ---------- Video path resolver ----------\n\ndef index_media_files(media_root: Path):\n    \"\"\"\n    Build maps for fast lookup by filename (with/without extension) and by stem.\n    Returns dicts: name2path, stem2paths\n    \"\"\"\n    files = list(media_root.glob(\"**/*.mp4\"))\n    name2path = {f.name: str(f) for f in files}\n    stem2paths = {}\n    for f in files:\n        stem2paths.setdefault(f.stem, []).append(str(f))\n    return name2path, stem2paths\n\nNAME2PATH, STEM2PATHS = index_media_files(MEDIA_ROOT)\n\ndef resolve_video_path(video_id_or_file: str, label_norm: str | None = None) -> str | None:\n    \"\"\"\n    Try multiple strategies:\n    1) Full filename match in media tree\n    2) Stem match (choose first)\n    3) If label is available (normal/hateful), try subfolder convention\n    \"\"\"\n    v = str(video_id_or_file).strip()\n    # 1) exact filename\n    if v in NAME2PATH:\n        return NAME2PATH[v]\n    # try with .mp4 ensure\n    if not v.lower().endswith(\".mp4\") and (v + \".mp4\") in NAME2PATH:\n        return NAME2PATH[v + \".mp4\"]\n    # 2) stem match\n    stem = v[:-4] if v.lower().endswith(\".mp4\") else v\n    cand = STEM2PATHS.get(stem)\n    if cand: return cand[0]\n    # 3) try subfolder using label\n    if label_norm:\n        sub = \"hate_videos\" if label_norm == \"hateful\" else \"non_hate_videos\"\n        p = MEDIA_ROOT / sub / (stem + \".mp4\")\n        if p.exists(): return str(p)\n    return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T03:22:45.923233Z","iopub.execute_input":"2025-09-19T03:22:45.923576Z","iopub.status.idle":"2025-09-19T03:22:49.671555Z","shell.execute_reply.started":"2025-09-19T03:22:45.923556Z","shell.execute_reply":"2025-09-19T03:22:49.670842Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load annotation\ndf_raw = pd.read_csv(ANN_PATH)\n\n# Resolve key columns (flexible names)\ncol_vid  = find_col(df_raw, \"video_id\", \"id\", \"video\", \"video_file_name\", \"filename\", \"file\")\ncol_lab  = find_col(df_raw, \"label\", \"class\", \"category\")\ncol_t0   = find_col(df_raw, \"start\", \"start_sec\", \"segment_start\", \"begin\")\ncol_t1   = find_col(df_raw, \"end\", \"end_sec\", \"segment_end\", \"finish\")\ncol_segL = find_col(df_raw, \"Segment-Level Label\", \"segmentlevellabel\", \"segmentlabel\")\ncol_segT = find_col(df_raw, \"Segment Timestamp\", \"segmenttimestamp\", \"timestamps\")\ncol_target = find_col(df_raw, \"target\", \"targets\", \"target_group\", \"targetgroup\")\n\nif col_vid is None or col_lab is None:\n    raise ValueError(f\"Missing essential columns in HateMM_annotation.csv. Found: {list(df_raw.columns)}\")\n\n# Normalize base columns\ndf = df_raw.copy()\ndf[\"video_id_raw\"] = df[col_vid].astype(str)\ndf[\"label\"] = df[col_lab].apply(normalize_label_string)\n\n# Parse target group (optional)\ndef parse_targets(x):\n    if isinstance(x, str):\n        if \"[\" in x or \"{\" in x:\n            lst = safe_parse_list(x); return [str(i) for i in lst] if lst else []\n        for sep in [\";\", \",\"]:\n            if sep in x: return [t.strip() for t in x.split(sep) if t.strip()]\n        return [x.strip()] if x.strip() else []\n    return []\ndf[\"target_group\"] = df[col_target].apply(parse_targets) if col_target else [[] for _ in range(len(df))]\n\n# Build records\nrecords = []\n\nif col_segL and col_segT:\n    # Case 1: segment-level labels & timestamps as lists (preferred if present)\n    for _, row in df.iterrows():\n        vid_key = row[\"video_id_raw\"]\n        labs_list = safe_parse_list(row[col_segL])\n        ts_list   = safe_parse_list(row[col_segT])\n        n = min(len(labs_list), len(ts_list))\n        for lb, ts in zip(labs_list[:n], ts_list[:n]):\n            # segment label could be string or list; normalize\n            if isinstance(lb, (list, tuple)):\n                # If HateMM uses only binary, take any non-normal as hateful\n                lbls = [normalize_label_string(\"hateful\" if any(bool(x) for x in lb) else \"normal\")]\n            else:\n                lbls = [normalize_label_string(lb)]\n            t0, t1 = parse_timestamp_pair(ts)\n            records.append({\n                \"dataset\": \"HateMM\",\n                \"video_id\": vid_key,\n                \"labels\": lbls,\n                \"start_sec\": t0, \"end_sec\": t1,\n                \"target_group\": row[\"target_group\"],\n            })\nelse:\n    # Case 2: video-level or per-row start/end present\n    for _, row in df.iterrows():\n        vid_key = row[\"video_id_raw\"]\n        # timestamps if exist\n        t0 = float(row[col_t0]) if col_t0 and pd.notna(row[col_t0]) else None\n        t1 = float(row[col_t1]) if col_t1 and pd.notna(row[col_t1]) else None\n        records.append({\n            \"dataset\": \"HateMM\",\n            \"video_id\": vid_key,\n            \"labels\": [row[\"label\"]],\n            \"start_sec\": t0, \"end_sec\": t1,\n            \"target_group\": row[\"target_group\"],\n        })\n\nhmm_multi = pd.DataFrame.from_records(records)\nprint(\"Raw samples (pre-path):\", len(hmm_multi))\nhmm_multi.head(3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T03:22:49.672536Z","iopub.execute_input":"2025-09-19T03:22:49.672758Z","iopub.status.idle":"2025-09-19T03:22:49.775216Z","shell.execute_reply.started":"2025-09-19T03:22:49.672734Z","shell.execute_reply":"2025-09-19T03:22:49.774601Z"}},"outputs":[{"name":"stdout","text":"Raw samples (pre-path): 1083\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  dataset              video_id     labels start_sec end_sec target_group\n0  HateMM      hate_video_1.mp4  [hateful]      None    None     [Blacks]\n1  HateMM      hate_video_2.mp4  [hateful]      None    None     [Blacks]\n2  HateMM  non_hate_video_1.mp4   [normal]      None    None     [Others]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>video_id</th>\n      <th>labels</th>\n      <th>start_sec</th>\n      <th>end_sec</th>\n      <th>target_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HateMM</td>\n      <td>hate_video_1.mp4</td>\n      <td>[hateful]</td>\n      <td>None</td>\n      <td>None</td>\n      <td>[Blacks]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HateMM</td>\n      <td>hate_video_2.mp4</td>\n      <td>[hateful]</td>\n      <td>None</td>\n      <td>None</td>\n      <td>[Blacks]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HateMM</td>\n      <td>non_hate_video_1.mp4</td>\n      <td>[normal]</td>\n      <td>None</td>\n      <td>None</td>\n      <td>[Others]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Resolve video_path using filename or stem + optional label hint\ndef guess_filename(vid_str: str) -> str:\n    \"\"\"\n    Many HateMM files are named like 'hate_video_4.mp4' or 'non_hate_video_18.mp4'.\n    If the raw video_id doesn't include .mp4, keep as-is; resolver will try variants.\n    \"\"\"\n    return vid_str if vid_str.lower().endswith(\".mp4\") else vid_str + \".mp4\"\n\npaths = []\nfor _, r in hmm_multi.iterrows():\n    # Prefer direct filename in annotation; otherwise try video_id variants\n    # Use first label as hint (for subfolder hate/non_hate)\n    label_hint = normalize_label_string(r[\"labels\"][0]) if isinstance(r[\"labels\"], list) and len(r[\"labels\"]) else None\n    p = resolve_video_path(guess_filename(r[\"video_id\"]), label_hint)\n    if p is None:\n        p = resolve_video_path(r[\"video_id\"], label_hint)\n    paths.append(p)\n\nhmm_multi[\"video_path\"] = paths\n\n# Explode to single-label rows\ndef explode_single_label_rows(df, labels_col=\"labels\", keep_cols=None):\n    if keep_cols is None:\n        keep_cols = [c for c in df.columns if c != labels_col]\n    rows = []\n    for _, r in df.iterrows():\n        labs = r[labels_col] if isinstance(r[labels_col], list) else safe_parse_list(r[labels_col])\n        if not labs: labs = [\"normal\"]\n        for lb in labs:\n            newr = {c: r[c] for c in keep_cols}\n            newr[\"label\"] = normalize_label_string(lb)\n            rows.append(newr)\n    return pd.DataFrame(rows)\n\nhmm_single = explode_single_label_rows(\n    hmm_multi,\n    labels_col=\"labels\",\n    keep_cols=[\"dataset\",\"video_id\",\"video_path\",\"start_sec\",\"end_sec\",\"target_group\"]\n)\n\n# Binary indicator (any non-normal considered offensive=1)\nhmm_single[\"binary_offensive\"] = hmm_single[\"label\"].apply(lambda s: int(s != \"normal\"))\n\n# sample_id\nhmm_single[\"sample_id\"] = hmm_single.apply(\n    lambda r: build_sample_id(r[\"dataset\"], r[\"video_id\"], r[\"start_sec\"], r[\"end_sec\"], r[\"label\"]), axis=1\n)\n\n# Save raw manifest (before cleaning)\nRAW_MANIFEST = OUT_DIR / \"hatemm_samples.csv\"\nhmm_single.to_csv(RAW_MANIFEST, index=False)\nprint(\"Saved raw HateMM manifest:\", RAW_MANIFEST, \"| rows:\", len(hmm_single))\nhmm_single.head(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T03:22:49.775974Z","iopub.execute_input":"2025-09-19T03:22:49.776221Z","iopub.status.idle":"2025-09-19T03:22:49.931242Z","shell.execute_reply.started":"2025-09-19T03:22:49.776202Z","shell.execute_reply":"2025-09-19T03:22:49.930601Z"}},"outputs":[{"name":"stdout","text":"Saved raw HateMM manifest: /kaggle/working/processed/hatemm_samples.csv | rows: 1083\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  dataset              video_id  \\\n0  HateMM      hate_video_1.mp4   \n1  HateMM      hate_video_2.mp4   \n2  HateMM  non_hate_video_1.mp4   \n3  HateMM      hate_video_3.mp4   \n4  HateMM  non_hate_video_2.mp4   \n\n                                          video_path start_sec end_sec  \\\n0  /kaggle/input/thesis-dataset/Thesis_dataset/ha...      None    None   \n1  /kaggle/input/thesis-dataset/Thesis_dataset/ha...      None    None   \n2  /kaggle/input/thesis-dataset/Thesis_dataset/no...      None    None   \n3  /kaggle/input/thesis-dataset/Thesis_dataset/ha...      None    None   \n4  /kaggle/input/thesis-dataset/Thesis_dataset/no...      None    None   \n\n  target_group    label  binary_offensive  \\\n0     [Blacks]  hateful                 1   \n1     [Blacks]  hateful                 1   \n2     [Others]   normal                 0   \n3     [Blacks]  hateful                 1   \n4     [Blacks]   normal                 0   \n\n                                     sample_id  \n0     HateMM__hate_video_1.mp4__0_end__hateful  \n1     HateMM__hate_video_2.mp4__0_end__hateful  \n2  HateMM__non_hate_video_1.mp4__0_end__normal  \n3     HateMM__hate_video_3.mp4__0_end__hateful  \n4  HateMM__non_hate_video_2.mp4__0_end__normal  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>video_id</th>\n      <th>video_path</th>\n      <th>start_sec</th>\n      <th>end_sec</th>\n      <th>target_group</th>\n      <th>label</th>\n      <th>binary_offensive</th>\n      <th>sample_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HateMM</td>\n      <td>hate_video_1.mp4</td>\n      <td>/kaggle/input/thesis-dataset/Thesis_dataset/ha...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>[Blacks]</td>\n      <td>hateful</td>\n      <td>1</td>\n      <td>HateMM__hate_video_1.mp4__0_end__hateful</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HateMM</td>\n      <td>hate_video_2.mp4</td>\n      <td>/kaggle/input/thesis-dataset/Thesis_dataset/ha...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>[Blacks]</td>\n      <td>hateful</td>\n      <td>1</td>\n      <td>HateMM__hate_video_2.mp4__0_end__hateful</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HateMM</td>\n      <td>non_hate_video_1.mp4</td>\n      <td>/kaggle/input/thesis-dataset/Thesis_dataset/no...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>[Others]</td>\n      <td>normal</td>\n      <td>0</td>\n      <td>HateMM__non_hate_video_1.mp4__0_end__normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HateMM</td>\n      <td>hate_video_3.mp4</td>\n      <td>/kaggle/input/thesis-dataset/Thesis_dataset/ha...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>[Blacks]</td>\n      <td>hateful</td>\n      <td>1</td>\n      <td>HateMM__hate_video_3.mp4__0_end__hateful</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HateMM</td>\n      <td>non_hate_video_2.mp4</td>\n      <td>/kaggle/input/thesis-dataset/Thesis_dataset/no...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>[Blacks]</td>\n      <td>normal</td>\n      <td>0</td>\n      <td>HateMM__non_hate_video_2.mp4__0_end__normal</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Robust duration probe\ndef ffprobe_duration(path: str) -> float | None:\n    cmd = f\"ffprobe -v error -show_entries format=duration -of default=nw=1:nk=1 {shlex.quote(str(path))}\"\n    try:\n        out = subprocess.check_output(shlex.split(cmd), stderr=subprocess.DEVNULL, text=True).strip()\n        dur = float(out)\n        return dur if (dur and dur > 0) else None\n    except Exception:\n        return None\n\ndef seg_len(row):\n    try:\n        if pd.notna(row.get(\"start_sec\")) and pd.notna(row.get(\"end_sec\")):\n            return max(0.0, float(row[\"end_sec\"]) - float(row[\"start_sec\"]))\n    except Exception:\n        pass\n    return np.nan\n\ndf = pd.read_csv(RAW_MANIFEST)\n\n# BEFORE stats\nbefore_rows  = len(df)\nbefore_paths = df[\"video_path\"].notna().sum()\nbefore_unique= df[\"video_path\"].nunique()\n\n# Probe duration\nuniq_paths = df[\"video_path\"].dropna().unique().tolist()\ndur_map = {p: ffprobe_duration(p) for p in uniq_paths}\ndf[\"video_seconds\"] = df[\"video_path\"].map(dur_map)\ndf[\"segment_seconds\"] = df.apply(seg_len, axis=1)\n\n# Mark unusable\ndf[\"is_broken\"] = df[\"video_seconds\"].isna()\n\n# Split kept/dropped\ndropped = df[df[\"is_broken\"]].copy()\nkept    = df[~df[\"is_broken\"]].copy()\n\n# AFTER stats\nafter_rows   = len(kept)\nafter_unique = kept[\"video_path\"].nunique()\ndrop_rows    = before_rows - after_rows\ndrop_rate    = (drop_rows / before_rows * 100.0) if before_rows else 0.0\n\nprint(f\"BEFORE: rows={before_rows}, unique paths={before_unique}\")\nprint(f\"AFTER : rows={after_rows}, unique paths={after_unique}, dropped={drop_rows} ({drop_rate:.2f}%)\")\n\n# Save cleaned + dropped lists\nCLEAN_MANIFEST = OUT_DIR / \"hatemm_samples.cleaned.csv\"\nDROP_LIST      = OUT_DIR / \"hatemm_samples.cleaned.dropped.csv\"\n\nkept.to_csv(CLEAN_MANIFEST, index=False)\ndropped.to_csv(DROP_LIST, index=False)\nprint(\"Saved:\", CLEAN_MANIFEST)\nprint(\"Dropped list:\", DROP_LIST)\n\n# Per-class tables (before/after)\nper_class_before = df.groupby(\"label\").size().rename(\"samples_before\").reset_index()\nper_class_after  = kept.groupby(\"label\").size().rename(\"samples_kept\").reset_index()\nper_class = per_class_before.merge(per_class_after, on=\"label\", how=\"outer\").fillna(0)\nper_class[\"samples_dropped\"] = per_class[\"samples_before\"] - per_class[\"samples_kept\"]\nper_class[\"drop_rate_%\"] = per_class.apply(\n    lambda r: (r[\"samples_dropped\"] / r[\"samples_before\"] * 100.0) if r[\"samples_before\"] else 0.0, axis=1\n)\nPER_CLASS_CSV = OUT_DIR / \"hatemm_cleaning_per_class.csv\"\nper_class.to_csv(PER_CLASS_CSV, index=False)\nprint(\"Saved per-class cleaning stats:\", PER_CLASS_CSV)\nper_class\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T03:22:49.933014Z","iopub.execute_input":"2025-09-19T03:22:49.933234Z","iopub.status.idle":"2025-09-19T03:25:05.690511Z","shell.execute_reply.started":"2025-09-19T03:22:49.933216Z","shell.execute_reply":"2025-09-19T03:25:05.689846Z"}},"outputs":[{"name":"stdout","text":"BEFORE: rows=1083, unique paths=1083\nAFTER : rows=1083, unique paths=1083, dropped=0 (0.00%)\nSaved: /kaggle/working/processed/hatemm_samples.cleaned.csv\nDropped list: /kaggle/working/processed/hatemm_samples.cleaned.dropped.csv\nSaved per-class cleaning stats: /kaggle/working/processed/hatemm_cleaning_per_class.csv\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     label  samples_before  samples_kept  samples_dropped  drop_rate_%\n0  hateful             431           431                0          0.0\n1   normal             652           652                0          0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>samples_before</th>\n      <th>samples_kept</th>\n      <th>samples_dropped</th>\n      <th>drop_rate_%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hateful</td>\n      <td>431</td>\n      <td>431</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>normal</td>\n      <td>652</td>\n      <td>652</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"hmm_clean = pd.read_csv(CLEAN_MANIFEST)\n\n# Per-class stats (cleaned only)\nstats = (\n    hmm_clean\n    .groupby(\"label\", dropna=False)\n    .agg(\n        samples=(\"sample_id\",\"count\"),\n        avg_video_seconds=(\"video_seconds\", \"mean\"),\n        avg_segment_seconds=(\"segment_seconds\", \"mean\"),\n    )\n    .reset_index()\n    .sort_values(\"label\")\n)\n\n# Overall (for the table \"ALL\" row)\noverall = pd.DataFrame([{\n    \"label\": \"ALL\",\n    \"samples\": len(hmm_clean),\n    \"avg_video_seconds\": hmm_clean[\"video_seconds\"].mean(),\n    \"avg_segment_seconds\": hmm_clean[\"segment_seconds\"].mean()\n}])\n\nstats_all = pd.concat([overall, stats], ignore_index=True)\n\n# Save for thesis\nSTATS_CSV = OUT_DIR / \"hatemm_statistics_cleaned.csv\"\nstats_all.to_csv(STATS_CSV, index=False)\nprint(\"Saved HateMM stats:\", STATS_CSV)\nstats_all\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T03:25:05.691363Z","iopub.execute_input":"2025-09-19T03:25:05.691683Z","iopub.status.idle":"2025-09-19T03:25:05.749537Z","shell.execute_reply.started":"2025-09-19T03:25:05.691662Z","shell.execute_reply":"2025-09-19T03:25:05.748785Z"}},"outputs":[{"name":"stdout","text":"Saved HateMM stats: /kaggle/working/processed/hatemm_statistics_cleaned.csv\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"     label  samples  avg_video_seconds  avg_segment_seconds\n0      ALL     1083         144.470157                  NaN\n1  hateful      431         154.517580                  NaN\n2   normal      652         137.828378                  NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>samples</th>\n      <th>avg_video_seconds</th>\n      <th>avg_segment_seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ALL</td>\n      <td>1083</td>\n      <td>144.470157</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hateful</td>\n      <td>431</td>\n      <td>154.517580</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>normal</td>\n      <td>652</td>\n      <td>137.828378</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# DataProcessing","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\nimport numpy as np\n\nOUT_DIR = Path(\"/kaggle/working/processed\")\nMANIFEST = OUT_DIR / \"hatemm_samples.cleaned.csv\"  # từ bước trước\nassert MANIFEST.exists(), \"Missing cleaned manifest. Run the cleaning step first.\"\n\n# Caching dirs\nCACHE_DIR = Path(\"/kaggle/working/cache_hatemm\")\nV_FEAT_DIR = CACHE_DIR / \"vision\"  # .npy per sample\nA_FEAT_DIR = CACHE_DIR / \"audio\"   # .npy per sample\nV_FRAME_DIR = CACHE_DIR / \"frames\" # extracted frames (intermediate)\nWAV_DIR = CACHE_DIR / \"wav\"        # extracted wav (intermediate)\n\nfor p in [V_FEAT_DIR, A_FEAT_DIR, V_FRAME_DIR, WAV_DIR]:\n    p.mkdir(parents=True, exist_ok=True)\n\n# Parameters\nFPS = 1.0               # frame sampling rate (frames per second)\nIMG_SIZE = 224          # input size for CLIP/ResNet\nMAX_FRAMES = 64         # cap frames per sample to avoid memory blow-up\nSR = 16000              # audio sample rate\nSEGMENT_PADDING = 0.0   # optional padding seconds around segments\n\ndf = pd.read_csv(MANIFEST)\nprint(\"Loaded cleaned manifest:\", len(df))\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T03:25:05.750335Z","iopub.execute_input":"2025-09-19T03:25:05.750864Z","iopub.status.idle":"2025-09-19T03:25:05.775130Z","shell.execute_reply.started":"2025-09-19T03:25:05.750837Z","shell.execute_reply":"2025-09-19T03:25:05.774323Z"}},"outputs":[{"name":"stdout","text":"Loaded cleaned manifest: 1083\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"  dataset              video_id  \\\n0  HateMM      hate_video_1.mp4   \n1  HateMM      hate_video_2.mp4   \n2  HateMM  non_hate_video_1.mp4   \n\n                                          video_path  start_sec  end_sec  \\\n0  /kaggle/input/thesis-dataset/Thesis_dataset/ha...        NaN      NaN   \n1  /kaggle/input/thesis-dataset/Thesis_dataset/ha...        NaN      NaN   \n2  /kaggle/input/thesis-dataset/Thesis_dataset/no...        NaN      NaN   \n\n  target_group    label  binary_offensive  \\\n0   ['Blacks']  hateful                 1   \n1   ['Blacks']  hateful                 1   \n2   ['Others']   normal                 0   \n\n                                     sample_id  video_seconds  \\\n0     HateMM__hate_video_1.mp4__0_end__hateful         94.998   \n1     HateMM__hate_video_2.mp4__0_end__hateful        129.160   \n2  HateMM__non_hate_video_1.mp4__0_end__normal        108.832   \n\n   segment_seconds  is_broken  \n0              NaN      False  \n1              NaN      False  \n2              NaN      False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>video_id</th>\n      <th>video_path</th>\n      <th>start_sec</th>\n      <th>end_sec</th>\n      <th>target_group</th>\n      <th>label</th>\n      <th>binary_offensive</th>\n      <th>sample_id</th>\n      <th>video_seconds</th>\n      <th>segment_seconds</th>\n      <th>is_broken</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HateMM</td>\n      <td>hate_video_1.mp4</td>\n      <td>/kaggle/input/thesis-dataset/Thesis_dataset/ha...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['Blacks']</td>\n      <td>hateful</td>\n      <td>1</td>\n      <td>HateMM__hate_video_1.mp4__0_end__hateful</td>\n      <td>94.998</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HateMM</td>\n      <td>hate_video_2.mp4</td>\n      <td>/kaggle/input/thesis-dataset/Thesis_dataset/ha...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['Blacks']</td>\n      <td>hateful</td>\n      <td>1</td>\n      <td>HateMM__hate_video_2.mp4__0_end__hateful</td>\n      <td>129.160</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HateMM</td>\n      <td>non_hate_video_1.mp4</td>\n      <td>/kaggle/input/thesis-dataset/Thesis_dataset/no...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>['Others']</td>\n      <td>normal</td>\n      <td>0</td>\n      <td>HateMM__non_hate_video_1.mp4__0_end__normal</td>\n      <td>108.832</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Vision feature caching","metadata":{}},{"cell_type":"code","source":"# Extract frames with ffmpeg, then encode with OpenCLIP ViT-B/32 (if available) or torchvision ResNet50.\nimport subprocess, shlex, math, os, glob, random\nfrom PIL import Image\nimport torch\nimport numpy as np\n\n# Try import open_clip; else fallback to torchvision\nBACKEND = None\ntry:\n    import open_clip\n    model_clip, _, preprocess = open_clip.create_model_and_transforms(\"ViT-B-32\", pretrained=\"openai\")\n    model_clip.eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    tok = open_clip.get_tokenizer(\"ViT-B-32\")\n    BACKEND = \"open_clip\"\nexcept Exception:\n    from torchvision import models, transforms\n    resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n    resnet.fc = torch.nn.Identity()\n    resnet.eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    preprocess = transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n    ])\n    BACKEND = \"resnet50\"\nprint(\"Vision backend:\", BACKEND)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef ffmpeg_extract_frames(video_path: str, out_dir: Path, start=None, end=None, fps=1.0, size=IMG_SIZE):\n    \"\"\"\n    Dump frames with ffmpeg at given FPS (optionally within [start, end]).\n    Returns a sorted list of file paths.\n    \"\"\"\n    out_dir.mkdir(parents=True, exist_ok=True)\n    # Clean previous\n    for f in out_dir.glob(\"*.jpg\"):\n        f.unlink(missing_ok=True)\n    ss = f\"-ss {start:.3f}\" if start is not None else \"\"\n    to = f\"-to {end:.3f}\" if end is not None else \"\"\n    vf = f\"fps={fps},scale={size}:{size}:force_original_aspect_ratio=decrease,pad={size}:{size}:(ow-iw)/2:(oh-ih)/2\"\n    cmd = (\n        f'ffmpeg -hide_banner -loglevel error -y {ss} -i {shlex.quote(video_path)} {to} '\n        f'-vf \"{vf}\" -qscale:v 2 {shlex.quote(str(out_dir / \"%05d.jpg\"))}'\n    )\n    subprocess.run(cmd, shell=True, check=False)\n    frames = sorted([str(p) for p in out_dir.glob(\"*.jpg\")])\n    return frames\n\n@torch.no_grad()\ndef encode_images(img_paths):\n    \"\"\"Encode a list of image paths into a single feature vector (temporal mean).\"\"\"\n    if not img_paths:\n        return None\n    if len(img_paths) > MAX_FRAMES:\n        # uniform subsample to MAX_FRAMES\n        idx = np.linspace(0, len(img_paths)-1, num=MAX_FRAMES).astype(int)\n        img_paths = [img_paths[i] for i in idx]\n\n    imgs = []\n    for p in img_paths:\n        try:\n            im = Image.open(p).convert(\"RGB\")\n            im = preprocess(im)\n            imgs.append(im)\n        except Exception:\n            continue\n    if not imgs:\n        return None\n\n    batch = torch.stack(imgs, dim=0).to(device)\n    if BACKEND == \"open_clip\":\n        feats = model_clip.encode_image(batch)\n        feats = torch.nn.functional.normalize(feats, dim=-1)  # cosine-friendly\n    else:\n        feats = resnet(batch)\n    feat = feats.mean(dim=0).detach().cpu().numpy()\n    return feat\n\ndef vision_cache_one(sample_id, video_path, start_sec, end_sec):\n    out_path = V_FEAT_DIR / f\"{sample_id}.npy\"\n    if out_path.exists():\n        return str(out_path)\n    # extract frames\n    s = None if pd.isna(start_sec) else float(start_sec) - SEGMENT_PADDING\n    e = None if pd.isna(end_sec) else float(end_sec) + SEGMENT_PADDING\n    if s is not None and e is not None and e <= s:  # guard\n        e = None\n    frame_dir = V_FRAME_DIR / sample_id\n    frames = ffmpeg_extract_frames(video_path, frame_dir, s, e, FPS, IMG_SIZE)\n    feat = encode_images(frames)\n    # cleanup frames to save disk\n    for f in frame_dir.glob(\"*.jpg\"):\n        f.unlink(missing_ok=True)\n    frame_dir.rmdir() if frame_dir.exists() and not any(frame_dir.iterdir()) else None\n    if feat is None:\n        return None\n    np.save(out_path, feat)\n    return str(out_path)\n\n# Run over manifest\nv_paths = []\nfor i, r in df.iterrows():\n    fp = vision_cache_one(r[\"sample_id\"], r[\"video_path\"], r.get(\"start_sec\"), r.get(\"end_sec\"))\n    v_paths.append(fp)\n    if (i+1) % 100 == 0:\n        print(f\"[Vision] {i+1}/{len(df)} cached\")\ndf[\"vision_feat_path\"] = v_paths\nprint(\"Vision feature cached. Examples:\", df[\"vision_feat_path\"].head(3).tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T03:25:05.775965Z","iopub.execute_input":"2025-09-19T03:25:05.776221Z","iopub.status.idle":"2025-09-19T04:09:19.304918Z","shell.execute_reply.started":"2025-09-19T03:25:05.776203Z","shell.execute_reply":"2025-09-19T04:09:19.304161Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 197MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Vision backend: resnet50\n[Vision] 100/1083 cached\n[Vision] 200/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"[mov,mp4,m4a,3gp,3g2,mj2 @ 0x58fd4fd3c540] stream 0, offset 0x23cc8c9: partial file\n/kaggle/input/thesis-dataset/Thesis_dataset/hate_videos/hate_video_95.mp4: Invalid data found when processing input\n[h264 @ 0x58fd4fe3a200] Invalid NAL unit size (1472 > 1168).\n[h264 @ 0x58fd4fe3a200] Error splitting the input into NAL units.\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x58fd4fd3c540] stream 0, offset 0x23cce16: partial file\n/kaggle/input/thesis-dataset/Thesis_dataset/hate_videos/hate_video_95.mp4: Invalid data found when processing input\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x58fd4fd3c540] stream 0, offset 0x23cd31e: partial file\n/kaggle/input/thesis-dataset/Thesis_dataset/hate_videos/hate_video_95.mp4: Invalid data found when processing input\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x58fd4fd3c540] stream 0, offset 0x23cd881: partial file\n/kaggle/input/thesis-dataset/Thesis_dataset/hate_videos/hate_video_95.mp4: Invalid data found when processing input\nError while decoding stream #0:0: Invalid data found when processing input\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x58fd4fd3c540] stream 0, offset 0x23ce0fb: partial file\n/kaggle/input/thesis-dataset/Thesis_dataset/hate_videos/hate_video_95.mp4: Invalid data found when processing input\n","output_type":"stream"},{"name":"stdout","text":"[Vision] 300/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"Output file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Vision] 400/1083 cached\n[Vision] 500/1083 cached\n[Vision] 600/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"Output file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Vision] 700/1083 cached\n[Vision] 800/1083 cached\n[Vision] 900/1083 cached\n[Vision] 1000/1083 cached\nVision feature cached. Examples: ['/kaggle/working/cache_hatemm/vision/HateMM__hate_video_1.mp4__0_end__hateful.npy', '/kaggle/working/cache_hatemm/vision/HateMM__hate_video_2.mp4__0_end__hateful.npy', '/kaggle/working/cache_hatemm/vision/HateMM__non_hate_video_1.mp4__0_end__normal.npy']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Audio feature caching (log-mel mean using librosa)","metadata":{}},{"cell_type":"code","source":"# Extract audio (wav) with ffmpeg, then compute log-mel and mean-pool over time.\nimport librosa, soundfile as sf\n\ndef ffmpeg_extract_wav(video_path: str, out_wav: Path, start=None, end=None, sr=SR):\n    out_wav.parent.mkdir(parents=True, exist_ok=True)\n    ss = f\"-ss {start:.3f}\" if start is not None else \"\"\n    to = f\"-to {end:.3f}\" if end is not None else \"\"\n    cmd = (\n        f'ffmpeg -hide_banner -loglevel error -y {ss} -i {shlex.quote(video_path)} {to} '\n        f'-ac 1 -ar {sr} -vn {shlex.quote(str(out_wav))}'\n    )\n    return subprocess.run(cmd, shell=True).returncode == 0 and out_wav.exists() and out_wav.stat().st_size > 0\n\ndef audio_cache_one(sample_id, video_path, start_sec, end_sec, n_mels=64, hop_length=320, win_length=1024):\n    out_path = A_FEAT_DIR / f\"{sample_id}.npy\"\n    if out_path.exists(): return str(out_path)\n    s = None if pd.isna(start_sec) else float(start_sec) - SEGMENT_PADDING\n    e = None if pd.isna(end_sec) else float(end_sec) + SEGMENT_PADDING\n    if s is not None and e is not None and e <= s:\n        e = None\n    wav_path = WAV_DIR / f\"{sample_id}.wav\"\n    ok = ffmpeg_extract_wav(video_path, wav_path, s, e, SR)\n    if not ok:\n        return None\n    try:\n        y, sr = librosa.load(str(wav_path), sr=SR, mono=True)\n        if y.size == 0:\n            return None\n        S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,\n                                           hop_length=hop_length, win_length=win_length, power=2.0)\n        logS = librosa.power_to_db(S, ref=np.max)\n        feat = logS.mean(axis=1).astype(np.float32)  # mean over time -> (n_mels,)\n        np.save(out_path, feat)\n        # cleanup wav to save disk\n        try: wav_path.unlink(missing_ok=True)\n        except: pass\n        return str(out_path)\n    except Exception:\n        try: wav_path.unlink(missing_ok=True)\n        except: pass\n        return None\n\na_paths = []\nfor i, r in df.iterrows():\n    fp = audio_cache_one(r[\"sample_id\"], r[\"video_path\"], r.get(\"start_sec\"), r.get(\"end_sec\"))\n    a_paths.append(fp)\n    if (i+1) % 100 == 0:\n        print(f\"[Audio] {i+1}/{len(df)} cached\")\ndf[\"audio_feat_path\"] = a_paths\nprint(\"Audio feature cached. Examples:\", df[\"audio_feat_path\"].head(3).tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T04:09:19.306607Z","iopub.execute_input":"2025-09-19T04:09:19.306978Z","iopub.status.idle":"2025-09-19T04:20:50.618714Z","shell.execute_reply.started":"2025-09-19T04:09:19.306959Z","shell.execute_reply":"2025-09-19T04:20:50.617864Z"}},"outputs":[{"name":"stderr","text":"Output file #0 does not contain any stream\nOutput file #0 does not contain any stream\nOutput file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Audio] 100/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"Output file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Audio] 200/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"Output file #0 does not contain any stream\n[mov,mp4,m4a,3gp,3g2,mj2 @ 0x5bfcdb518500] stream 1, offset 0x23ce62e: partial file\n/kaggle/input/thesis-dataset/Thesis_dataset/hate_videos/hate_video_95.mp4: Invalid data found when processing input\nOutput file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Audio] 300/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"Output file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Audio] 400/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"Output file #0 does not contain any stream\nOutput file #0 does not contain any stream\nOutput file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Audio] 500/1083 cached\n[Audio] 600/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"Output file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Audio] 700/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"Output file #0 does not contain any stream\nOutput file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Audio] 800/1083 cached\n[Audio] 900/1083 cached\n","output_type":"stream"},{"name":"stderr","text":"Output file #0 does not contain any stream\nOutput file #0 does not contain any stream\n","output_type":"stream"},{"name":"stdout","text":"[Audio] 1000/1083 cached\nAudio feature cached. Examples: ['/kaggle/working/cache_hatemm/audio/HateMM__hate_video_1.mp4__0_end__hateful.npy', '/kaggle/working/cache_hatemm/audio/HateMM__hate_video_2.mp4__0_end__hateful.npy', '/kaggle/working/cache_hatemm/audio/HateMM__non_hate_video_1.mp4__0_end__normal.npy']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"# Keep only rows that have at least one feature (vision or audio)\nusable = df[(df[\"vision_feat_path\"].notna()) | (df[\"audio_feat_path\"].notna())].copy()\nusable[\"has_vision\"] = usable[\"vision_feat_path\"].notna()\nusable[\"has_audio\"]  = usable[\"audio_feat_path\"].notna()\n\nTRAIN_MANIFEST = OUT_DIR / \"hatemm_train_manifest.csv\"\nusable.to_csv(TRAIN_MANIFEST, index=False)\nprint(\"Saved training manifest:\", TRAIN_MANIFEST, \"| rows:\", len(usable))\nusable[[\"sample_id\",\"label\",\"vision_feat_path\",\"audio_feat_path\"]].head(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T04:20:50.619571Z","iopub.execute_input":"2025-09-19T04:20:50.620057Z","iopub.status.idle":"2025-09-19T04:20:50.654781Z","shell.execute_reply.started":"2025-09-19T04:20:50.620036Z","shell.execute_reply":"2025-09-19T04:20:50.654163Z"}},"outputs":[{"name":"stdout","text":"Saved training manifest: /kaggle/working/processed/hatemm_train_manifest.csv | rows: 1083\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                     sample_id    label  \\\n0     HateMM__hate_video_1.mp4__0_end__hateful  hateful   \n1     HateMM__hate_video_2.mp4__0_end__hateful  hateful   \n2  HateMM__non_hate_video_1.mp4__0_end__normal   normal   \n3     HateMM__hate_video_3.mp4__0_end__hateful  hateful   \n4  HateMM__non_hate_video_2.mp4__0_end__normal   normal   \n\n                                    vision_feat_path  \\\n0  /kaggle/working/cache_hatemm/vision/HateMM__ha...   \n1  /kaggle/working/cache_hatemm/vision/HateMM__ha...   \n2  /kaggle/working/cache_hatemm/vision/HateMM__no...   \n3  /kaggle/working/cache_hatemm/vision/HateMM__ha...   \n4  /kaggle/working/cache_hatemm/vision/HateMM__no...   \n\n                                     audio_feat_path  \n0  /kaggle/working/cache_hatemm/audio/HateMM__hat...  \n1  /kaggle/working/cache_hatemm/audio/HateMM__hat...  \n2  /kaggle/working/cache_hatemm/audio/HateMM__non...  \n3  /kaggle/working/cache_hatemm/audio/HateMM__hat...  \n4                                               None  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>label</th>\n      <th>vision_feat_path</th>\n      <th>audio_feat_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HateMM__hate_video_1.mp4__0_end__hateful</td>\n      <td>hateful</td>\n      <td>/kaggle/working/cache_hatemm/vision/HateMM__ha...</td>\n      <td>/kaggle/working/cache_hatemm/audio/HateMM__hat...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HateMM__hate_video_2.mp4__0_end__hateful</td>\n      <td>hateful</td>\n      <td>/kaggle/working/cache_hatemm/vision/HateMM__ha...</td>\n      <td>/kaggle/working/cache_hatemm/audio/HateMM__hat...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HateMM__non_hate_video_1.mp4__0_end__normal</td>\n      <td>normal</td>\n      <td>/kaggle/working/cache_hatemm/vision/HateMM__no...</td>\n      <td>/kaggle/working/cache_hatemm/audio/HateMM__non...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HateMM__hate_video_3.mp4__0_end__hateful</td>\n      <td>hateful</td>\n      <td>/kaggle/working/cache_hatemm/vision/HateMM__ha...</td>\n      <td>/kaggle/working/cache_hatemm/audio/HateMM__hat...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HateMM__non_hate_video_2.mp4__0_end__normal</td>\n      <td>normal</td>\n      <td>/kaggle/working/cache_hatemm/vision/HateMM__no...</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from pathlib import Path\nimport shutil, json\n\nROOT = Path(\"/kaggle/working/processed\")\nassert (ROOT/\"hatemm_samples.cleaned.csv\").exists(), \"Run the cleaning steps first.\"\n\n# --- lựa chọn export ---\nEXPORT_FEATURES = True  # True nếu muốn kèm các .npy (nặng nhưng train ngay)\n\n# Danh sách file tối thiểu cho Notebook B\nto_copy = [\n    ROOT/\"hatemm_samples.cleaned.csv\",\n    ROOT/\"hatemm_train_manifest.csv\",       # từ Cell 11 trước đó\n    ROOT/\"hatemm_statistics_cleaned.csv\",   # bảng thống kê\n    ROOT/\"hatemm_cleaning_per_class.csv\", # nếu có\n    ROOT/\"hatemm_samples.csv\",  # nếu có\n    ROOT/\"label2id.json\" if (ROOT/\"label2id.json\").exists() else None,\n]\nto_copy = [p for p in to_copy if p and p.exists()]\n\n# Thêm features nếu cần\nextra_dirs = []\nif EXPORT_FEATURES:\n    extra_dirs += [\n        Path(\"/kaggle/working/cache_hatemm/vision\"),\n        Path(\"/kaggle/working/cache_hatemm/audio\"),\n        Path(\"/kaggle/working/cache_hatemm/frame\"),\n        Path(\"/kaggle/working/cache_hatemm/wav\")\n    ]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:01:42.081278Z","iopub.execute_input":"2025-09-19T05:01:42.081563Z","iopub.status.idle":"2025-09-19T05:01:42.088584Z","shell.execute_reply.started":"2025-09-19T05:01:42.081540Z","shell.execute_reply":"2025-09-19T05:01:42.087837Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# /kaggle/working/cache_hatemm\nfrom pathlib import Path\nimport zipfile\nfrom datetime import datetime\n\nEXPORT_DIR = Path(\"/kaggle/working/export_hatemm\")\nEXPORT_DIR.mkdir(parents=True, exist_ok=True)\n\nversion = datetime.now().strftime(\"%Y%m%d_%H%M\")\nzip_path = EXPORT_DIR / f\"hatemm_processed_{version}.zip\"\n\nreadme = f\"\"\"HateMM processed package\nVersion: {version}\n\nContents:\n- hatemm_samples.cleaned.csv : cleaned manifest (one row = one label/segment)\n- hatemm_train_manifest.csv  : training manifest with feature paths (if features included)\n- hatemm_statistics_cleaned.csv : dataset statistics (per-class, avg lengths)\n- cleaning_summary_*.csv : drop stats before/after cleaning\n- label2id.json : label mapping used in training (if present)\n{\"- features/vision/*.npy and features/audio/*.npy : cached features (optional)\" if True else \"\"}\n\nHow to use in a new notebook:\n1) Unzip to a working folder\n2) If no features inside, re-run feature caching (or reuse your Cell 9–12)\n3) Load manifests, build X/Y matrices, and train baseline.\n\"\"\"\n\n# build zip\nwith zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n    # files\n    for p in to_copy:\n        zf.write(p, arcname=p.name)\n    # features (optional)\n    if EXPORT_FEATURES:\n        for d in extra_dirs:\n            if d.exists():\n                for npy in d.rglob(\"*.npy\"):\n                    # put under features/vision or features/audio\n                    rel = Path(\"features\") / d.name / npy.name\n                    zf.write(npy, arcname=str(rel))\n    # readme\n    zf.writestr(\"README.txt\", readme)\n\nprint(\"Created:\", zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T05:01:46.650472Z","iopub.execute_input":"2025-09-19T05:01:46.651183Z","iopub.status.idle":"2025-09-19T05:01:47.233874Z","shell.execute_reply.started":"2025-09-19T05:01:46.651159Z","shell.execute_reply":"2025-09-19T05:01:47.232985Z"}},"outputs":[{"name":"stdout","text":"Created: /kaggle/working/export_hatemm/hatemm_processed_20250919_0501.zip\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"extra_dirs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}