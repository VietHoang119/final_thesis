{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13044847,"sourceType":"datasetVersion","datasetId":8260282}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# # Multimodal Harmful Video Detection ‚Äî Preprocess & Train\n# This notebook processes three datasets (MultiHateClip EN, HateMM, HateClipSeg),\n# unifies metadata, extracts audio/frames/text, and trains simple baselines.\n# Runtime: Kaggle (GPU T4). Make sure \"Accelerator: GPU\" is ON.\n\nimport sys, platform, subprocess, os, shutil\n\nprint(\"Python:\", sys.version)\nprint(\"Platform:\", platform.platform())\nprint(\"CUDA visible:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n!nvidia-smi -L || true\n!ffmpeg -version | head -n 1 || true","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:21:13.919574Z","iopub.execute_input":"2025-09-14T03:21:13.919841Z","iopub.status.idle":"2025-09-14T03:21:14.769672Z","shell.execute_reply.started":"2025-09-14T03:21:13.919816Z","shell.execute_reply":"2025-09-14T03:21:14.769023Z"}},"outputs":[{"name":"stdout","text":"Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nPlatform: Linux-6.6.56+-x86_64-with-glibc2.35\nCUDA visible: None\nGPU 0: Tesla T4 (UUID: GPU-5925937c-09a8-6d89-19b9-f71168e72bb6)\nGPU 1: Tesla T4 (UUID: GPU-11f0a912-56f6-8367-9cea-d9a49160448c)\nffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# %% [markdown]\n# ## Install dependencies\n# We use PyTorch + transformers + librosa + faster-whisper, and some utils.\n\n!pip -q install --upgrade pip\n!pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n!pip -q install transformers==4.43.3 librosa==0.10.2.post1 soundfile==0.12.1 \\\n                     opencv-python==4.10.0.84 faster-whisper==1.0.3 \\\n                     pandas pyarrow numpy tqdm joblib scikit-learn ffmpeg-python==0.2.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:21:14.770999Z","iopub.execute_input":"2025-09-14T03:21:14.771310Z","iopub.status.idle":"2025-09-14T03:21:20.811940Z","shell.execute_reply.started":"2025-09-14T03:21:14.771283Z","shell.execute_reply":"2025-09-14T03:21:20.811102Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# %% [markdown]\n# ## Directory config (EDIT: set RAW_BASE to your Kaggle mounted dataset name)\nfrom pathlib import Path\n\nROOT = Path(\"/kaggle/working\")\nDATA = ROOT / \"data\"\nRAW = DATA / \"raw\"\nPROC = DATA / \"processed\"\nMETA = DATA / \"metadata\"\nfor p in [RAW, PROC, META]:\n    p.mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:21:20.813031Z","iopub.execute_input":"2025-09-14T03:21:20.813353Z","iopub.status.idle":"2025-09-14T03:21:20.818695Z","shell.execute_reply.started":"2025-09-14T03:21:20.813316Z","shell.execute_reply":"2025-09-14T03:21:20.818184Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# >>> IMPORTANT <<<\n# Mount your whole local tree as a Kaggle dataset (e.g. \"preprocess_lab\").\n# Then set RAW_BASE to that input path:\nRAW_BASE = Path(\"/kaggle/input/dataset-sample/preprocess_lab\")  # <-- EDIT to your actual mount name\n\n# Your real structure inside RAW_BASE (mirrors what you showed):\n# HateClipSeg:\nHCS_ROOT   = RAW_BASE / \"data\" / \"raw\" / \"HateClipSeg\"\nHCS_VLEVEL = HCS_ROOT / \"data\" / \"video_level\"    # full videos\nHCS_SLEVEL = HCS_ROOT / \"data\" / \"segment_level\"  # may contain same videos or pre-cut clips\nHCS_SEGCSV = HCS_ROOT / \"segment_level_annotation.csv\"\nHCS_VIDCSV = HCS_ROOT / \"video_level_annotation.csv\"\n\n# HateMM:\nHMM_ROOT   = RAW_BASE / \"data\" / \"raw\" / \"HateMM\"\nHMM_ANN    = HMM_ROOT / \"HateMM_annotation.csv\"\nHMM_HATE   = HMM_ROOT / \"data\" / \"hate_videos\"\nHMM_NHATE  = HMM_ROOT / \"data\" / \"non_hate_videos\"\n\n# MultiHateClip:\nMHC_ROOT   = RAW_BASE / \"data\" / \"raw\" / \"MultiHateClip\"\nMHC_DATA   = MHC_ROOT / \"data\"\nMHC_TRAIN  = MHC_DATA / \"train\"\nMHC_VALID  = MHC_DATA / \"valid\"\nMHC_TEST   = MHC_DATA / \"test\"\nMHC_TRAIN_TSV = MHC_ROOT / \"train.tsv\"\nMHC_VALID_TSV = MHC_ROOT / \"valid.tsv\"\nMHC_TEST_TSV  = MHC_ROOT / \"test.tsv\"\n\n# Processing knobs\nFPS = 1\nFRAME_SIZE = (224, 224)\nSAMPLE_RATE = 16000\nASR_MODEL = \"small.en\"\nMIN_DUR = 1.5\n\nEXTRACT_FRAMES = True\nEXTRACT_AUDIO  = True\nEXTRACT_MELS   = True\nRUN_ASR        = True\nCUT_SEGMENTS   = True  # set False if HCS segment_level already provides pre-cut segments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:26:06.587396Z","iopub.execute_input":"2025-09-14T03:26:06.588032Z","iopub.status.idle":"2025-09-14T03:26:06.594649Z","shell.execute_reply.started":"2025-09-14T03:26:06.588006Z","shell.execute_reply":"2025-09-14T03:26:06.593963Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# %% [markdown]\n# ## Utilities: ffmpeg, mel, ASR\nimport subprocess, librosa, numpy as np, soundfile as sf\nfrom tqdm import tqdm\n\ndef run(cmd): subprocess.run(cmd, check=True)\n\ndef hhmmss(seconds: float) -> str:\n    ms = int(round(seconds * 1000))\n    s = ms/1000.0\n    hh = int(s//3600); s -= hh*3600\n    mm = int(s//60); s -= mm*60\n    return f\"{hh:02d}:{mm:02d}:{s:06.3f}\"\n\ndef ffmpeg_extract_audio(in_mp4: Path, out_wav: Path, sr=16000):\n    out_wav.parent.mkdir(parents=True, exist_ok=True)\n    run([\"ffmpeg\",\"-hide_banner\",\"-loglevel\",\"error\",\"-i\",str(in_mp4),\n         \"-ac\",\"1\",\"-ar\",str(sr),\"-vn\",\"-y\",str(out_wav)])\n\ndef ffmpeg_extract_frames(in_mp4: Path, out_dir: Path, fps=1, size=(224,224)):\n    out_dir.mkdir(parents=True, exist_ok=True)\n    w,h = size\n    run([\"ffmpeg\",\"-hide_banner\",\"-loglevel\",\"error\",\"-i\",str(in_mp4),\n         \"-r\",str(fps),\"-vf\",f\"scale={w}:{h}\",str(out_dir / \"%06d.jpg\")])\n\ndef ffmpeg_cut_segment(in_mp4: Path, start_s: float, dur_s: float, out_mp4: Path):\n    out_mp4.parent.mkdir(parents=True, exist_ok=True)\n    run([\"ffmpeg\",\"-hide_banner\",\"-loglevel\",\"error\",\"-ss\",hhmmss(start_s),\n         \"-i\",str(in_mp4),\"-t\",f\"{dur_s:.3f}\",\n         \"-c:v\",\"libx264\",\"-preset\",\"veryfast\",\"-crf\",\"23\",\"-c:a\",\"aac\",\"-y\",str(out_mp4)])\n\ndef save_mel(wav_path: Path, out_npy: Path, sr=16000, n_mels=64):\n    y, sr_ = librosa.load(wav_path, sr=sr, mono=True)\n    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n    S_db = librosa.power_to_db(S, ref=np.max)\n    out_npy.parent.mkdir(parents=True, exist_ok=True)\n    np.save(out_npy, S_db)\n\nfrom faster_whisper import WhisperModel\nclass ASR:\n    def __init__(self, model_size=\"small.en\", device=\"auto\", compute_type=\"float16\"):\n        self.model = WhisperModel(model_size, device=device, compute_type=compute_type)\n    def transcribe(self, audio_path: Path) -> str:\n        segs, _ = self.model.transcribe(str(audio_path), beam_size=5, vad_filter=True)\n        return \" \".join([s.text.strip() for s in segs]).strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:30:54.893291Z","iopub.execute_input":"2025-09-14T03:30:54.893820Z","iopub.status.idle":"2025-09-14T03:30:54.903499Z","shell.execute_reply.started":"2025-09-14T03:30:54.893795Z","shell.execute_reply":"2025-09-14T03:30:54.902774Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# %% [markdown]\n# ## Label mapping helpers\nimport pandas as pd\nfrom pathlib import Path\n\ndef map_mhc_bin(lbl: str) -> int:\n    return 0 if str(lbl).strip().lower()==\"normal\" else 1\n\ndef map_hmm_bin(lbl: str) -> int:\n    return 1 if str(lbl).strip().lower() in [\"hate\",\"hateful\",\"offensive\"] else 0\n\ndef map_hcs_multiclass(lbl: str) -> str:\n    L = str(lbl).strip().lower()\n    if L in [\"normal\",\"hateful\",\"insulting\",\"sexual\",\"violence\",\"self-harm\"]:\n        return L.capitalize()\n    return \"Normal\"\n\ndef map_hcs_bin(lbl: str) -> int:\n    return 0 if str(lbl).strip().lower()==\"normal\" else 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:30:58.836277Z","iopub.execute_input":"2025-09-14T03:30:58.836791Z","iopub.status.idle":"2025-09-14T03:30:58.842022Z","shell.execute_reply.started":"2025-09-14T03:30:58.836759Z","shell.execute_reply":"2025-09-14T03:30:58.841347Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# %% [markdown]\n# ## HateClipSeg: robust parser for ['Video Id', 'Segment-Level Label', 'Segment Timestamp']\n# Handles many formats, including nested-list strings and missing commas.\n\nimport re, ast, json\nimport pandas as pd\nfrom pathlib import Path\n\nassert HCS_SEGCSV.exists(), f\"Missing {HCS_SEGCSV}\"\ndf_raw = pd.read_csv(HCS_SEGCSV)\n\nREQ_COLS = [\"Video Id\", \"Segment-Level Label\", \"Segment Timestamp\"]\nmissing = [c for c in REQ_COLS if c not in df_raw.columns]\nassert not missing, f\"CSV missing columns: {missing} | Found: {list(df_raw.columns)}\"\n\nDEFAULT_HALF_WIN = 1.5  # seconds for single-timestamp cases\n\n# ---------- time parsers ----------\ndef time_to_seconds(token: str) -> float:\n    \"\"\"Accepts 'hh:mm:ss(.ms)', 'mm:ss(.ms)', or plain float seconds.\"\"\"\n    t = token.strip()\n    # HH:MM:SS(.ms)\n    if re.match(r\"^\\d{1,2}:\\d{1,2}:\\d{1,2}(\\.\\d+)?$\", t):\n        h, m, s = t.split(\":\")\n        return int(h) * 3600 + int(m) * 60 + float(s)\n    # MM:SS(.ms)\n    if re.match(r\"^\\d{1,2}:\\d{1,2}(\\.\\d+)?$\", t):\n        m, s = t.split(\":\")\n        return int(m) * 60 + float(s)\n    # float seconds\n    return float(t)\n\ndef normalize_list_string(s: str) -> str:\n    \"\"\"\n    Normalize weird list-like strings:\n      - Remove double brackets [[...]] -> [...]\n      - Ensure commas between items if only whitespace separates numbers/ times\n    \"\"\"\n    x = s.strip()\n    # Strip outer brackets multiple levels\n    x = re.sub(r\"^\\s*\\[+\\s*\", \"[\", x)\n    x = re.sub(r\"\\s*\\]+\\s*$\", \"]\", x)\n\n    # If there are quotes-separated tokens without comma, insert comma\n    # e.g., \"['0.00' '3.00']\" -> \"['0.00','3.00']\"\n    x = re.sub(r\"'\\s+'\", \"','\", x)\n    x = re.sub(r'\"\\s+\"', '\",\"', x)\n\n    # Also handle bare numbers/times separated by whitespace inside brackets: [0.0 3.0] -> [0.0,3.0]\n    # Only apply inside [...] to avoid affecting normal strings\n    def _insert_commas_inside_brackets(m):\n        inner = m.group(1)\n        # if already has comma, keep\n        if \",\" in inner:\n            return \"[\" + inner + \"]\"\n        # put comma between number/time tokens separated by whitespace\n        tokens = inner.strip().split()\n        return \"[\" + \",\".join(tokens) + \"]\"\n\n    x = re.sub(r\"\\[\\s*([^\\[\\]]+?)\\s*\\]\", lambda m: _insert_commas_inside_brackets(m), x)\n    return x\n\ndef try_parse_as_list(ts: str):\n    \"\"\"\n    Try to parse ts as JSON or Python literal list.\n    Returns list[str] or None.\n    \"\"\"\n    s = normalize_list_string(ts)\n    # Try JSON first\n    try:\n        val = json.loads(s)\n        # flatten 2D lists like [[\"0.00\",\"3.00\"]]\n        while isinstance(val, list) and len(val)==1 and isinstance(val[0], list):\n            val = val[0]\n        if isinstance(val, list):\n            return [str(v) for v in val]\n    except Exception:\n        pass\n    # Try Python literal\n    try:\n        val = ast.literal_eval(s)\n        while isinstance(val, list) and len(val)==1 and isinstance(val[0], list):\n            val = val[0]\n        if isinstance(val, list):\n            return [str(v) for v in val]\n    except Exception:\n        pass\n    return None\n\ndef parse_segment_timestamp(ts) -> tuple:\n    \"\"\"\n    Return (start_s, end_s) floats.\n    Strategy:\n      1) If list-like -> take first two entries.\n      2) Else split by separators (-, ‚Äì, ‚Äî, 'to', comma) and parse first two parts.\n      3) Else single timestamp -> ¬±DEFAULT_HALF_WIN.\n    \"\"\"\n    if pd.isna(ts) or str(ts).strip()==\"\":\n        return None, None\n    s = str(ts).strip()\n\n    # (1) list-like?\n    as_list = try_parse_as_list(s)\n    if as_list:\n        if len(as_list) >= 2:\n            a, b = as_list[0], as_list[1]\n            a_s, b_s = time_to_seconds(a), time_to_seconds(b)\n            if b_s < a_s: a_s, b_s = b_s, a_s\n            return a_s, b_s\n        elif len(as_list) == 1:\n            t = time_to_seconds(as_list[0])\n            return max(0.0, t-DEFAULT_HALF_WIN), t+DEFAULT_HALF_WIN\n\n    # (2) split by common separators\n    s_norm = re.sub(r\"\\s*(‚Äì|‚Äî|to)\\s*\", \"-\", s, flags=re.IGNORECASE)\n    parts = [p for chunk in s_norm.split(\",\") for p in chunk.split(\"-\")]\n    parts = [p.strip() for p in parts if p.strip()!=\"\"]\n    if len(parts) >= 2:\n        a_s, b_s = time_to_seconds(parts[0]), time_to_seconds(parts[1])\n        if b_s < a_s: a_s, b_s = b_s, a_s\n        return a_s, b_s\n    elif len(parts) == 1:\n        t = time_to_seconds(parts[0])\n        return max(0.0, t-DEFAULT_HALF_WIN), t+DEFAULT_HALF_WIN\n\n    return None, None\n\ndef resolve_hcs_video_path(video_id: str) -> Path:\n    \"\"\"\n    Map 'Video Id' to actual .mp4 file.\n    Prefer video_level/, fallback to segment_level/. Try explicit 'bit_' prefix too.\n    \"\"\"\n    v = str(video_id).strip()\n    candidates = []\n    if v.endswith(\".mp4\"):\n        candidates.append(v)\n    else:\n        candidates += [f\"{v}.mp4\", f\"bit_{v}.mp4\"]\n\n    for name in candidates:\n        p1 = HCS_VLEVEL / name\n        if p1.exists(): return p1\n        p2 = HCS_SLEVEL / name\n        if p2.exists(): return p2\n    # last-shot: as-is in video_level\n    return HCS_VLEVEL / (v if v.endswith(\".mp4\") else f\"{v}.mp4\")\n\n# ---------- build output & collect rejects ----------\nrows, rejects = [], []\nfor i, r in df_raw.iterrows():\n    vid = r[\"Video Id\"]\n    label = r[\"Segment-Level Label\"]\n    ts = r[\"Segment Timestamp\"]\n\n    try:\n        start_s, end_s = parse_segment_timestamp(ts)\n        if start_s is None or end_s is None:\n            raise ValueError(f\"Unparsed ts: {ts}\")\n        vpath = resolve_hcs_video_path(vid)\n        stem = Path(vpath).stem\n        seg_id = f\"{stem}_{int(round(start_s*1000))}_{int(round(end_s*1000))}\"\n        rows.append({\n            \"seg_id\": seg_id,\n            \"video_path\": str(vpath),\n            \"start\": float(start_s),\n            \"end\": float(end_s),\n            \"label\": str(label),\n            \"target_group\": \"\"\n        })\n    except Exception as e:\n        rejects.append({\"idx\": i, \"Video Id\": vid, \"Segment-Level Label\": label, \"Segment Timestamp\": ts, \"error\": str(e)})\n\nhcs_seg_df = pd.DataFrame(rows)\nprint(\"HateClipSeg segments parsed:\", hcs_seg_df.shape)\ndisplay(hcs_seg_df.head(5))\n\n# Save rejects for inspection, if any\nrej_path = META / \"hcs_timestamp_rejects.csv\"\nif rejects:\n    pd.DataFrame(rejects).to_csv(rej_path, index=False)\n    print(f\"Saved rejects -> {rej_path}  (count={len(rejects)})\")\nelse:\n    print(\"No rejects üéâ\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:31:03.822691Z","iopub.execute_input":"2025-09-14T03:31:03.823025Z","iopub.status.idle":"2025-09-14T03:31:04.021987Z","shell.execute_reply.started":"2025-09-14T03:31:03.823002Z","shell.execute_reply":"2025-09-14T03:31:04.021278Z"}},"outputs":[{"name":"stdout","text":"HateClipSeg segments parsed: (2, 6)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                      seg_id  \\\n0  bit_tD1tyOy1HOJH_0_201160   \n1  bit_ty1ffKOFCEnl_0_290550   \n\n                                          video_path  start     end  \\\n0  /kaggle/input/dataset-sample/preprocess_lab/da...    0.0  201.16   \n1  /kaggle/input/dataset-sample/preprocess_lab/da...    0.0  290.55   \n\n                  label target_group  \n0  [[1, 0, 0, 0, 0, 0]]               \n1  [[1, 0, 0, 0, 0, 0]]               ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seg_id</th>\n      <th>video_path</th>\n      <th>start</th>\n      <th>end</th>\n      <th>label</th>\n      <th>target_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bit_tD1tyOy1HOJH_0_201160</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>0.0</td>\n      <td>201.16</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bit_ty1ffKOFCEnl_0_290550</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>0.0</td>\n      <td>290.55</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Saved rejects -> /kaggle/working/data/metadata/hcs_timestamp_rejects.csv  (count=433)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# %% [markdown]\n# ## HateMM: parser for ['video_file_name', 'label', 'hate_snippet', 'target']\n# - Resolves video path under data/{hate_videos, non_hate_videos}\n# - Parses optional timestamps from 'hate_snippet' if present; else uses full segment.\n\nimport re, ast, json\nimport pandas as pd\nfrom pathlib import Path\n\nassert HMM_ANN.exists(), f\"Missing {HMM_ANN}\"\nhmm_raw = pd.read_csv(HMM_ANN)\n\nREQ = [\"video_file_name\", \"label\"]\nmissing = [c for c in REQ if c not in hmm_raw.columns]\nassert not missing, f\"CSV missing columns: {missing} | Found: {list(hmm_raw.columns)}\"\n\n# ---------- time helpers (reuse logic from HCS robust parser) ----------\nDEFAULT_HALF_WIN = 1.5  # seconds\n\ndef time_to_seconds(token: str) -> float:\n    t = str(token).strip()\n    if re.match(r\"^\\d{1,2}:\\d{1,2}:\\d{1,2}(\\.\\d+)?$\", t):\n        h, m, s = t.split(\":\"); return int(h)*3600 + int(m)*60 + float(s)\n    if re.match(r\"^\\d{1,2}:\\d{1,2}(\\.\\d+)?$\", t):\n        m, s = t.split(\":\"); return int(m)*60 + float(s)\n    return float(t)\n\ndef normalize_list_string(s: str) -> str:\n    x = s.strip()\n    x = re.sub(r\"^\\s*\\[+\\s*\", \"[\", x)\n    x = re.sub(r\"\\s*\\]+\\s*$\", \"]\", x)\n    x = re.sub(r\"'\\s+'\", \"','\", x)\n    x = re.sub(r'\"\\s+\"', '\",\"', x)\n    def _inside(m):\n        inner = m.group(1)\n        if \",\" in inner: return \"[\" + inner + \"]\"\n        toks = inner.strip().split()\n        return \"[\" + \",\".join(toks) + \"]\"\n    x = re.sub(r\"\\[\\s*([^\\[\\]]+?)\\s*\\]\", lambda m: _inside(m), x)\n    return x\n\ndef try_parse_as_list(ts: str):\n    s = normalize_list_string(ts)\n    try:\n        val = json.loads(s)\n        while isinstance(val, list) and len(val)==1 and isinstance(val[0], list):\n            val = val[0]\n        if isinstance(val, list): return [str(v) for v in val]\n    except Exception:\n        pass\n    try:\n        val = ast.literal_eval(s)\n        while isinstance(val, list) and len(val)==1 and isinstance(val[0], list):\n            val = val[0]\n        if isinstance(val, list): return [str(v) for v in val]\n    except Exception:\n        pass\n    return None\n\ndef parse_timestamp_flexible(ts) -> tuple:\n    \"\"\"\n    Try to extract (start,end) from hate_snippet if it looks time-like.\n    Returns (start_s, end_s) or (None, None) if not parseable.\n    \"\"\"\n    if ts is None or (isinstance(ts, float) and pd.isna(ts)): \n        return None, None\n    s = str(ts).strip()\n    if s == \"\": return None, None\n\n    # 1) list-like?\n    as_list = try_parse_as_list(s)\n    if as_list:\n        if len(as_list) >= 2:\n            a, b = as_list[0], as_list[1]\n            a_s, b_s = time_to_seconds(a), time_to_seconds(b)\n            if b_s < a_s: a_s, b_s = b_s, a_s\n            return a_s, b_s\n        elif len(as_list) == 1:\n            t = time_to_seconds(as_list[0])\n            return max(0.0, t-DEFAULT_HALF_WIN), t+DEFAULT_HALF_WIN\n\n    # 2) split by separators: '-', en-dash, 'to', comma\n    s_norm = re.sub(r\"\\s*(‚Äì|‚Äî|to)\\s*\", \"-\", s, flags=re.IGNORECASE)\n    parts = [p for chunk in s_norm.split(\",\") for p in chunk.split(\"-\")]\n    parts = [p.strip() for p in parts if p.strip()!=\"\"]\n    # Accept only if parts look like time tokens (avoid random text)\n    def looks_time(x): \n        return bool(re.match(r\"^\\d+(\\.\\d+)?$\", x) or re.match(r\"^\\d{1,2}:\\d{1,2}(:\\d{1,2}(\\.\\d+)?)?$\", x))\n    parts_time = [p for p in parts if looks_time(p)]\n    if len(parts_time) >= 2:\n        a_s, b_s = time_to_seconds(parts_time[0]), time_to_seconds(parts_time[1])\n        if b_s < a_s: a_s, b_s = b_s, a_s\n        return a_s, b_s\n    if len(parts_time) == 1:\n        t = time_to_seconds(parts_time[0])\n        return max(0.0, t-DEFAULT_HALF_WIN), t+DEFAULT_HALF_WIN\n\n    return None, None\n\n# ---------- path resolver ----------\ndef resolve_hmm_path(basename: str) -> Path:\n    \"\"\"\n    Try both hate and non_hate dirs; handle presence/absence of .mp4.\n    \"\"\"\n    v = str(basename).strip()\n    cands = [v, f\"{v}.mp4\"] if not v.endswith(\".mp4\") else [v]\n    for name in cands:\n        p = HMM_HATE / name\n        if p.exists(): return p\n        p2 = HMM_NHATE / name\n        if p2.exists(): return p2\n    # last fallback\n    return HMM_HATE / (v if v.endswith(\".mp4\") else f\"{v}.mp4\")\n\n# ---------- build rows ----------\nrows, rejects = [], []\nhas_target = \"target\" in hmm_raw.columns\nhas_snip   = \"hate_snippet\" in hmm_raw.columns\n\nfor i, r in hmm_raw.iterrows():\n    vid   = r[\"video_file_name\"]\n    label = r[\"label\"]\n    tgt   = (str(r[\"target\"]) if has_target and pd.notna(r[\"target\"]) else \"\")\n    snip  = (r[\"hate_snippet\"] if has_snip else None)\n\n    vpath = resolve_hmm_path(vid)\n\n    # Try to parse timestamps from snippet; else full segment\n    start_s, end_s = parse_timestamp_flexible(snip)\n    if start_s is None or end_s is None:\n        # mark as full; preprocess step will copy full video (dur=None sentinel)\n        seg_id = f\"{Path(vpath).stem}_full\"\n        rows.append({\n            \"seg_id\": seg_id,\n            \"video_path\": str(vpath),\n            \"start\": 0.0,\n            \"end\": 1e9,  # sentinel for full\n            \"label\": str(label),\n            \"target\": tgt\n        })\n    else:\n        seg_id = f\"{Path(vpath).stem}_{int(round(start_s*1000))}_{int(round(end_s*1000))}\"\n        rows.append({\n            \"seg_id\": seg_id,\n            \"video_path\": str(vpath),\n            \"start\": float(start_s),\n            \"end\": float(end_s),\n            \"label\": str(label),\n            \"target\": tgt\n        })\n\nhmm_seg_df = pd.DataFrame(rows)\nprint(\"HateMM segments parsed:\", hmm_seg_df.shape)\ndisplay(hmm_seg_df.head(5))\n\n# Save lines where snippet looked time-like but failed (none in this pass since we fall back).\nrej_path = META / \"hatemm_timestamp_rejects.csv\"\nif rejects:\n    pd.DataFrame(rejects).to_csv(rej_path, index=False)\n    print(f\"Saved rejects -> {rej_path}\")\nelse:\n    print(\"No rejects üéâ\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:31:13.250449Z","iopub.execute_input":"2025-09-14T03:31:13.251392Z","iopub.status.idle":"2025-09-14T03:31:13.418027Z","shell.execute_reply.started":"2025-09-14T03:31:13.251358Z","shell.execute_reply":"2025-09-14T03:31:13.417450Z"}},"outputs":[{"name":"stdout","text":"HateMM segments parsed: (1083, 6)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                     seg_id  \\\n0  hate_video_1_34000_94000   \n1  hate_video_2_6000_126000   \n2     non_hate_video_1_full   \n3         hate_video_3_full   \n4     non_hate_video_2_full   \n\n                                          video_path  start           end  \\\n0  /kaggle/input/dataset-sample/preprocess_lab/da...   34.0  9.400000e+01   \n1  /kaggle/input/dataset-sample/preprocess_lab/da...    6.0  1.260000e+02   \n2  /kaggle/input/dataset-sample/preprocess_lab/da...    0.0  1.000000e+09   \n3  /kaggle/input/dataset-sample/preprocess_lab/da...    0.0  1.000000e+09   \n4  /kaggle/input/dataset-sample/preprocess_lab/da...    0.0  1.000000e+09   \n\n      label  target  \n0      Hate  Blacks  \n1      Hate  Blacks  \n2  Non Hate  Others  \n3      Hate  Blacks  \n4  Non Hate  Blacks  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seg_id</th>\n      <th>video_path</th>\n      <th>start</th>\n      <th>end</th>\n      <th>label</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hate_video_1_34000_94000</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>34.0</td>\n      <td>9.400000e+01</td>\n      <td>Hate</td>\n      <td>Blacks</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hate_video_2_6000_126000</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>6.0</td>\n      <td>1.260000e+02</td>\n      <td>Hate</td>\n      <td>Blacks</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>non_hate_video_1_full</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>0.0</td>\n      <td>1.000000e+09</td>\n      <td>Non Hate</td>\n      <td>Others</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hate_video_3_full</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>0.0</td>\n      <td>1.000000e+09</td>\n      <td>Hate</td>\n      <td>Blacks</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>non_hate_video_2_full</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>0.0</td>\n      <td>1.000000e+09</td>\n      <td>Non Hate</td>\n      <td>Blacks</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"No rejects üéâ\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# %% [markdown]\n# ## MultiHateClip: parse `train.tsv`, `valid.tsv`, `test.tsv`\n# Expected per line: <video_id>\\t<label>. Map to data/{train,valid,test}.\n\nimport csv  # <-- b·ªï sung ƒë·ªÉ d√πng csv.reader\nimport pandas as pd\nfrom pathlib import Path\n\ndef read_tsv(tsv_path: Path):\n    rows=[]\n    with open(tsv_path, newline='', encoding='utf-8') as f:\n        rd = csv.reader(f, delimiter='\\t')\n        for row in rd:\n            if not row: \n                continue\n            # b·ªè header n·∫øu c√≥\n            if len(row) >= 2 and row[0].lower() in [\"video_id\",\"id\"] and row[1].lower() in [\"label\",\"class\"]:\n                continue\n            # m·ªôt s·ªë t·ªáp th·ª±c ch·∫•t l√† csv ch·ª© kh√¥ng ph·∫£i tsv\n            if len(row) < 2 and ',' in row[0]:\n                parts = row[0].split(',')\n                if len(parts) >= 2:\n                    rows.append({\"video_id\": parts[0].strip(), \"label\": parts[1].strip()})\n                continue\n            if len(row) >= 2:\n                rows.append({\"video_id\": row[0].strip(), \"label\": row[1].strip()})\n    return pd.DataFrame(rows)\n\ndef mhc_map_path(vid: str, split_dir: Path) -> Path:\n    # x·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p id c√≥ ti·ªÅn t·ªë '-' ho·∫∑c '_' trong t√™n file\n    p = split_dir / vid\n    if p.exists(): return p\n    if not vid.endswith(\".mp4\"):\n        p2 = split_dir / f\"{vid}.mp4\"\n        if p2.exists(): return p2\n    cand = vid.lstrip(\"-_\")\n    p3 = split_dir / cand\n    if p3.exists(): return p3\n    if not cand.endswith(\".mp4\"):\n        p4 = split_dir / f\"{cand}.mp4\"\n        if p4.exists(): return p4\n    matches = list(split_dir.glob(f\"*{Path(vid).stem}*.mp4\"))\n    return matches[0] if matches else split_dir / (vid if vid.endswith(\".mp4\") else f\"{vid}.mp4\")\n\ndfs=[]\nif MHC_TRAIN_TSV.exists():\n    d = read_tsv(MHC_TRAIN_TSV); d[\"split\"]=\"train\"; dfs.append(d)\nif MHC_VALID_TSV.exists():\n    d = read_tsv(MHC_VALID_TSV); d[\"split\"]=\"valid\"; dfs.append(d)\nif MHC_TEST_TSV.exists():\n    d = read_tsv(MHC_TEST_TSV);  d[\"split\"]=\"test\";  dfs.append(d)\n\nmhc_lbl = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\nprint(\"Loaded MHC rows:\", mhc_lbl.shape)\n\nmhc_rows=[]\nfor _, r in mhc_lbl.iterrows():\n    sp = r[\"split\"]\n    split_dir = {\"train\": MHC_TRAIN, \"valid\": MHC_VALID, \"test\": MHC_TEST}[sp]\n    path = mhc_map_path(str(r[\"video_id\"]), split_dir)\n    mhc_rows.append({\"video_id\": str(r[\"video_id\"]), \"video_path\": str(path), \"label\": str(r[\"label\"]), \"split\": sp})\nmhc_df = pd.DataFrame(mhc_rows)\nprint(\"MultiHateClip mapped:\", mhc_df.shape)\ndisplay(mhc_df.head(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:31:17.184136Z","iopub.execute_input":"2025-09-14T03:31:17.184411Z","iopub.status.idle":"2025-09-14T03:31:17.981615Z","shell.execute_reply.started":"2025-09-14T03:31:17.184392Z","shell.execute_reply":"2025-09-14T03:31:17.981041Z"}},"outputs":[{"name":"stdout","text":"Loaded MHC rows: (1004, 3)\nMultiHateClip mapped: (1004, 4)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      video_id                                         video_path  \\\n0     Video_ID  /kaggle/input/dataset-sample/preprocess_lab/da...   \n1  4V0KGql_fUI  /kaggle/input/dataset-sample/preprocess_lab/da...   \n2  5snzFreG79c  /kaggle/input/dataset-sample/preprocess_lab/da...   \n\n             label  split  \n0  Majority_Voting  train  \n1           Normal  train  \n2        Offensive  train  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_id</th>\n      <th>video_path</th>\n      <th>label</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Video_ID</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>Majority_Voting</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4V0KGql_fUI</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>Normal</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5snzFreG79c</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>Offensive</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# %% [markdown]\n# ## Save normalized label CSVs for the preprocessing stage\nlabs_dir = META / \"labels_raw\"\nlabs_dir.mkdir(parents=True, exist_ok=True)\n\nLAB_HC = labs_dir / \"hateclipseg_segments.csv\"       # seg_id, video_path, start, end, label, target_group\nLAB_MM = labs_dir / \"hatemm_spans.csv\"               # seg_id, video_path, start, end, label\nLAB_MH = labs_dir / \"multihateclip_en.csv\"           # video_id, video_path, label, split\n\nhcs_seg_df.to_csv(LAB_HC, index=False)\nhmm_seg_df.to_csv(LAB_MM, index=False)\nmhc_df.to_csv(LAB_MH, index=False)\n\nprint(\"Wrote:\")\nprint(\"-\", LAB_HC)\nprint(\"-\", LAB_MM)\nprint(\"-\", LAB_MH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:31:21.036703Z","iopub.execute_input":"2025-09-14T03:31:21.037037Z","iopub.status.idle":"2025-09-14T03:31:21.055332Z","shell.execute_reply.started":"2025-09-14T03:31:21.037007Z","shell.execute_reply":"2025-09-14T03:31:21.054779Z"}},"outputs":[{"name":"stdout","text":"Wrote:\n- /kaggle/working/data/metadata/labels_raw/hateclipseg_segments.csv\n- /kaggle/working/data/metadata/labels_raw/hatemm_spans.csv\n- /kaggle/working/data/metadata/labels_raw/multihateclip_en.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# %% [markdown]\n# ## Force-override ASR class (safe on CPU/GPU) + quick probe\n# This cell deletes any previous ASR definitions, defines a safe wrapper, and prints the chosen config.\n\nimport os\nfrom faster_whisper import WhisperModel\n\n# 1) Remove any previous ASR definitions\ntry:\n    del ASR  # old class that used compute_type=\"float16\"\nexcept NameError:\n    pass\n\ndef pick_fw_config(prefer_size=\"small.en\"):\n    \"\"\"Pick a safe (device, compute_type, model_size) for faster-whisper.\"\"\"\n    # If Kaggle gives us a GPU, CUDA_VISIBLE_DEVICES is typically set; otherwise fall back to CPU.\n    has_cuda = os.environ.get(\"CUDA_VISIBLE_DEVICES\") not in (None, \"\", \"-1\")\n\n    if has_cuda:\n        # 'int8_float16' is fast & memory-friendly on most Kaggle GPUs.\n        # If it still fails, our class below will fall back to 'int8'.\n        return (\"cuda\", \"int8_float16\", prefer_size)\n    else:\n        # Pure CPU: 'int8' keeps memory and speed reasonable.\n        return (\"cpu\", \"int8\", prefer_size)\n\nclass ASR:\n    \"\"\"Safe ASR wrapper that never hard-codes float16; includes graceful fallbacks.\"\"\"\n    def __init__(self, model_size=\"small.en\"):\n        device, compute_type, msize = pick_fw_config(prefer_size=model_size)\n        self._cfg = (device, compute_type, msize)\n        # try preferred config\n        try:\n            self.model = WhisperModel(msize, device=device, compute_type=compute_type)\n            self._ok = True\n        except ValueError as e:\n            # If float16 path or chosen type not supported, fall back stepwise.\n            self._ok = False\n            # 1) try int8 on same device\n            try:\n                self.model = WhisperModel(msize, device=device, compute_type=\"int8\")\n                self._ok = True\n                self._cfg = (device, \"int8\", msize)\n            except Exception:\n                # 2) final fallback: CPU + int8\n                self.model = WhisperModel(msize, device=\"cpu\", compute_type=\"int8\")\n                self._ok = True\n                self._cfg = (\"cpu\", \"int8\", msize)\n\n    def transcribe(self, audio_path):\n        segments, _ = self.model.transcribe(str(audio_path), beam_size=5, vad_filter=True)\n        return \" \".join([s.text.strip() for s in segments]).strip()\n\n# Optional: force a lighter model to speed up CPU runs\nASR_MODEL = \"base.en\"  # or \"tiny.en\" if CPU is slow\n\n# Quick probe (no audio I/O; just show picked config)\nprint(\"ASR will use (device, compute_type, model):\", ASR(ASR_MODEL)._cfg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:31:45.875257Z","iopub.execute_input":"2025-09-14T03:31:45.875819Z","iopub.status.idle":"2025-09-14T03:31:46.392864Z","shell.execute_reply.started":"2025-09-14T03:31:45.875794Z","shell.execute_reply":"2025-09-14T03:31:46.392071Z"}},"outputs":[{"name":"stdout","text":"ASR will use (device, compute_type, model): ('cpu', 'int8', 'base.en')\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# %% [markdown]\n# ## Quick audit: which HateClipSeg video files are missing?\nfrom pathlib import Path\nimport pandas as pd\n\nLAB_HC = META / \"labels_raw\" / \"hateclipseg_segments.csv\"\nhc_df = pd.read_csv(LAB_HC)\n\ndef exists(p): \n    try: return Path(p).exists()\n    except: return False\n\nhc_df[\"exists\"] = hc_df[\"video_path\"].apply(exists)\nmissing = hc_df[~hc_df[\"exists\"]].copy()\nprint(f\"Total HCS rows: {len(hc_df)} | missing files: {len(missing)}\")\ndisplay(missing.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:31:56.153254Z","iopub.execute_input":"2025-09-14T03:31:56.153521Z","iopub.status.idle":"2025-09-14T03:31:56.178838Z","shell.execute_reply.started":"2025-09-14T03:31:56.153501Z","shell.execute_reply":"2025-09-14T03:31:56.178244Z"}},"outputs":[{"name":"stdout","text":"Total HCS rows: 2 | missing files: 2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                      seg_id  \\\n0  bit_tD1tyOy1HOJH_0_201160   \n1  bit_ty1ffKOFCEnl_0_290550   \n\n                                          video_path  start     end  \\\n0  /kaggle/input/dataset-sample/preprocess_lab/da...    0.0  201.16   \n1  /kaggle/input/dataset-sample/preprocess_lab/da...    0.0  290.55   \n\n                  label  target_group  exists  \n0  [[1, 0, 0, 0, 0, 0]]           NaN   False  \n1  [[1, 0, 0, 0, 0, 0]]           NaN   False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seg_id</th>\n      <th>video_path</th>\n      <th>start</th>\n      <th>end</th>\n      <th>label</th>\n      <th>target_group</th>\n      <th>exists</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bit_tD1tyOy1HOJH_0_201160</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>0.0</td>\n      <td>201.16</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bit_ty1ffKOFCEnl_0_290550</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>0.0</td>\n      <td>290.55</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# %% [markdown]\n# ## Smarter resolver for HateClipSeg file paths + remap\nfrom pathlib import Path\nimport pandas as pd\nimport re\n\n# ƒê·∫£m b·∫£o b·∫°n ƒë√£ set ƒë√∫ng RAW_BASE tr∆∞·ªõc ƒë√≥.\n# ·ªû log l·ªói m√¨nh th·∫•y: /kaggle/input/dataset-sample/preprocess_lab/...\n# V·∫≠y RAW_BASE n√™n l√†:\nRAW_BASE = Path(\"/kaggle/input/dataset-sample/preprocess_lab\")  # ch·ªânh n·∫øu kh√°c\nHCS_ROOT   = RAW_BASE / \"data\" / \"raw\" / \"HateClipSeg\"\nHCS_VLEVEL = HCS_ROOT / \"data\" / \"video_level\"\nHCS_SLEVEL = HCS_ROOT / \"data\" / \"segment_level\"\n\ndef smart_glob(stem: str):\n    \"\"\"\n    T√¨m file b·∫±ng wildcard theo stem (kh√¥ng ph·∫ßn ƒëu√¥i). Th·ª≠ c·∫£ 2 th∆∞ m·ª•c.\n    V√≠ d·ª• stem='bit_abc123' -> t√¨m *abc123*.mp4\n    \"\"\"\n    pats = [f\"*{stem}*.mp4\", f\"*{stem}*\"]\n    cands = []\n    for d in [HCS_VLEVEL, HCS_SLEVEL]:\n        for pat in pats:\n            cands += list(d.glob(pat))\n    return cands\n\ndef resolve_hcs_video_path_smart(original_path: str):\n    \"\"\"\n    - N·∫øu original_path t·ªìn t·∫°i -> tr·∫£ v·ªÅ lu√¥n\n    - Th·ª≠ c√°c bi·∫øn th·ªÉ t√™n file: c√≥/kh√¥ng .mp4, th√™m/b·ªõt 'bit_' v√† 'yt_'\n    - N·∫øu ch∆∞a ra -> wildcard theo stem\n    - N·∫øu v·∫´n ch∆∞a -> tr·∫£ v·ªÅ None\n    \"\"\"\n    p = Path(original_path)\n    if p.exists():\n        return p\n\n    name = p.name\n    stem = Path(name).stem\n    trials = []\n\n    # th∆∞ m·ª•c ∆∞u ti√™n: video_level -> segment_level\n    # 1) nguy√™n b·∫£n\n    trials += [HCS_VLEVEL / name, HCS_SLEVEL / name]\n    # 2) th√™m .mp4\n    if not name.endswith(\".mp4\"):\n        trials += [HCS_VLEVEL / f\"{name}.mp4\", HCS_SLEVEL / f\"{name}.mp4\"]\n\n    # 3) th√™m/b·ªõt ti·ªÅn t·ªë\n    prefixes = [\"\", \"bit_\", \"yt_\"]\n    base = stem\n    # n·∫øu stem ƒë√£ c√≥ bit_/yt_ th√¨ th·ª≠ b·ªè ƒëi\n    base_noprefix = re.sub(r\"^(bit_|yt_)\", \"\", stem)\n    variants = set()\n    for pf in prefixes:\n        variants.add(pf + base)\n        variants.add(pf + base_noprefix)\n\n    for v in variants:\n        trials += [HCS_VLEVEL / f\"{v}.mp4\", HCS_SLEVEL / f\"{v}.mp4\",\n                   HCS_VLEVEL / v,         HCS_SLEVEL / v]\n\n    # 4) wildcard\n    if not any(t.exists() for t in trials):\n        # t√¨m theo c·∫£ stem v√† base_noprefix\n        globs = smart_glob(stem) + smart_glob(base_noprefix)\n        if globs:\n            return globs[0]\n        return None\n\n    for t in trials:\n        if t.exists():\n            return t\n    return None\n\n# Remap to√†n b·ªô HCS video_path v·ªõi resolver m·ªõi\nhc_df = pd.read_csv(LAB_HC)\nnew_paths = []\nfor vp in hc_df[\"video_path\"].tolist():\n    rp = resolve_hcs_video_path_smart(vp)\n    new_paths.append(\"\" if rp is None else str(rp))\n\nhc_df[\"video_path_resolved\"] = new_paths\nhc_df[\"exists\"] = hc_df[\"video_path_resolved\"].apply(lambda x: Path(x).exists() if isinstance(x, str) and x else False)\nprint(\"Missing after smart resolve:\", int((~hc_df[\"exists\"]).sum()))\ndisplay(hc_df[~hc_df[\"exists\"]].head(10))\n\n# Ghi ƒë√® file labels ƒë·ªÉ preprocess d√πng ƒë∆∞·ªùng d·∫´n ƒë√£ resolve\nhc_df_use = hc_df.copy()\nhc_df_use[\"video_path\"] = hc_df_use[\"video_path_resolved\"]\nhc_df_use = hc_df_use.drop(columns=[\"video_path_resolved\",\"exists\"])\nhc_df_use.to_csv(LAB_HC, index=False)\nprint(\"Rewrote:\", LAB_HC)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:35:03.704114Z","iopub.execute_input":"2025-09-14T03:35:03.704436Z","iopub.status.idle":"2025-09-14T03:35:03.794771Z","shell.execute_reply.started":"2025-09-14T03:35:03.704416Z","shell.execute_reply":"2025-09-14T03:35:03.794196Z"}},"outputs":[{"name":"stdout","text":"Missing after smart resolve: 2\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                      seg_id  \\\n0  bit_tD1tyOy1HOJH_0_201160   \n1  bit_ty1ffKOFCEnl_0_290550   \n\n                                          video_path  start     end  \\\n0  /kaggle/input/dataset-sample/preprocess_lab/da...    0.0  201.16   \n1  /kaggle/input/dataset-sample/preprocess_lab/da...    0.0  290.55   \n\n                  label  target_group video_path_resolved  exists  \n0  [[1, 0, 0, 0, 0, 0]]           NaN                       False  \n1  [[1, 0, 0, 0, 0, 0]]           NaN                       False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seg_id</th>\n      <th>video_path</th>\n      <th>start</th>\n      <th>end</th>\n      <th>label</th>\n      <th>target_group</th>\n      <th>video_path_resolved</th>\n      <th>exists</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bit_tD1tyOy1HOJH_0_201160</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>0.0</td>\n      <td>201.16</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n      <td>NaN</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bit_ty1ffKOFCEnl_0_290550</td>\n      <td>/kaggle/input/dataset-sample/preprocess_lab/da...</td>\n      <td>0.0</td>\n      <td>290.55</td>\n      <td>[[1, 0, 0, 0, 0, 0]]</td>\n      <td>NaN</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Rewrote: /kaggle/working/data/metadata/labels_raw/hateclipseg_segments.csv\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# %% [markdown]\n# ## Safer preprocess_hateclipseg: skip-missing + dur clamp via ffprobe\nimport json, subprocess\nfrom pathlib import Path\nimport pandas as pd\nfrom tqdm import tqdm\n\ndef ffprobe_duration_seconds(path: Path) -> float:\n    \"\"\"\n    Return duration in seconds using ffprobe. Returns None if probing fails.\n    \"\"\"\n    try:\n        cmd = [\n            \"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n            \"-of\", \"json\", str(path)\n        ]\n        out = subprocess.check_output(cmd)\n        j = json.loads(out.decode(\"utf-8\"))\n        dur = float(j[\"format\"][\"duration\"])\n        return dur\n    except Exception:\n        return None\n\ndef preprocess_hateclipseg(df: pd.DataFrame) -> pd.DataFrame:\n    rec=[]; missing_rows=[]\n    asr = ASR(ASR_MODEL) if RUN_ASR else None\n\n    for r in tqdm(df.to_dict(orient=\"records\"), desc=\"HateClipSeg\"):\n        in_mp4 = Path(r[\"video_path\"])\n        if not in_mp4.exists():\n            # log missing and continue\n            missing_rows.append(r)\n            continue\n\n        start, end = float(r[\"start\"]), float(r[\"end\"])\n        raw_dur = max(0.0, end - start)\n        if raw_dur < MIN_DUR:\n            continue\n\n        # Clamp duration by actual file duration if available\n        vid_dur = ffprobe_duration_seconds(in_mp4)\n        dur = raw_dur\n        if vid_dur is not None:\n            # ƒë√¥i khi annotation end v∆∞·ª£t file length 1‚Äì2s; clamp l·∫°i\n            max_dur = max(0.0, vid_dur - start)\n            dur = min(raw_dur, max_dur) if max_dur > 0 else raw_dur\n            if dur < MIN_DUR:\n                continue\n\n        seg_id = str(r[\"seg_id\"])\n        out_seg = PROC / \"segments\" / \"hateclipseg\" / f\"{seg_id}.mp4\"\n        src = out_seg\n        if CUT_SEGMENTS:\n            if not out_seg.exists():\n                ffmpeg_cut_segment(in_mp4, start, dur, out_seg)\n        else:\n            src = in_mp4\n\n        audio = PROC / \"audio\" / \"hateclipseg\" / f\"{seg_id}.wav\"\n        frames_dir = PROC / \"frames\" / \"hateclipseg\" / seg_id\n        mel = PROC / \"mels\" / \"hateclipseg\" / f\"{seg_id}.npy\"\n        txt = PROC / \"text\" / \"hateclipseg\" / f\"{seg_id}.txt\"\n\n        if EXTRACT_AUDIO and not audio.exists(): ffmpeg_extract_audio(src, audio, SAMPLE_RATE)\n        if EXTRACT_FRAMES and not frames_dir.exists(): ffmpeg_extract_frames(src, frames_dir, FPS, FRAME_SIZE)\n        if EXTRACT_MELS and not mel.exists(): save_mel(audio, mel, SAMPLE_RATE)\n        if RUN_ASR and not txt.exists():\n            txt.parent.mkdir(parents=True, exist_ok=True)\n            txt.write_text(asr.transcribe(audio), encoding=\"utf-8\")\n\n        rec.append({\n            \"dataset\":\"HateClipSeg\",\"sample_id\":seg_id,\n            \"video_path\":str(in_mp4),\"segment_path\":str(out_seg),\n            \"audio_path\":str(audio),\"frames_dir\":str(frames_dir),\n            \"mel_path\":str(mel),\"text_path\":str(txt),\n            \"start\":start,\"end\":end,\"duration\":dur,\n            \"label_multiclass\": r.get(\"label_multiclass\", r.get(\"label\", \"\")),\n            \"label_bin\": 0 if str(r.get(\"label\",\"\")).strip().lower()==\"normal\" else 1,\n            \"target_group\": r.get(\"target_group\",\"\")\n        })\n\n    # Save missing for review\n    if missing_rows:\n        miss_path = META / \"hcs_missing_files.csv\"\n        pd.DataFrame(missing_rows).to_csv(miss_path, index=False)\n        print(f\"[HateClipSeg] Missing files logged -> {miss_path} (n={len(missing_rows)})\")\n\n    return pd.DataFrame.from_records(rec)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:35:17.537872Z","iopub.execute_input":"2025-09-14T03:35:17.538179Z","iopub.status.idle":"2025-09-14T03:35:17.550001Z","shell.execute_reply.started":"2025-09-14T03:35:17.538157Z","shell.execute_reply":"2025-09-14T03:35:17.549449Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"dfs=[]\nhc_df = pd.read_csv(LAB_HC)\nmm_df = pd.read_csv(META / \"labels_raw\" / \"hatemm_spans.csv\")\nmh_df = pd.read_csv(META / \"labels_raw\" / \"multihateclip_en.csv\")\n\nif len(hc_df): dfs.append(preprocess_hateclipseg(hc_df))\nif len(mm_df): dfs.append(preprocess_hatemm(mm_df))\nif len(mh_df): dfs.append(preprocess_multihateclip(mh_df))\n\nmeta = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\nprint(\"Total processed samples:\", len(meta))\ndisplay(meta.head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:35:27.820290Z","iopub.execute_input":"2025-09-14T03:35:27.821072Z","iopub.status.idle":"2025-09-14T03:35:28.336103Z","shell.execute_reply.started":"2025-09-14T03:35:27.821042Z","shell.execute_reply":"2025-09-14T03:35:28.335162Z"}},"outputs":[{"name":"stderr","text":"HateClipSeg:   0%|          | 0/2 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/440054321.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmh_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETA\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"labels_raw\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"multihateclip_en.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhc_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_hateclipseg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhc_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_hatemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmh_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_multihateclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmh_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/989940739.py\u001b[0m in \u001b[0;36mpreprocess_hateclipseg\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"records\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HateClipSeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0min_mp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"video_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_mp4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# log missing and continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindowsPath\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mPosixPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             raise NotImplementedError(\"cannot instantiate %r on your system\"\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# right flavour.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mparts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                     \u001b[0;31m# Force-cast str subclasses to str (issue #21127)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not float"],"ename":"TypeError","evalue":"expected str, bytes or os.PathLike object, not float","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"# %% [markdown]\n# ## Preprocess: cut/extract features for HateClipSeg, HateMM, MultiHateClip\n# Assumes you already defined:\n# - PROC, META\n# - functions: ffmpeg_cut_segment, ffmpeg_extract_audio, ffmpeg_extract_frames, save_mel, ASR\n# - toggles: CUT_SEGMENTS, EXTRACT_AUDIO, EXTRACT_FRAMES, EXTRACT_MELS, RUN_ASR\n# - constants: SAMPLE_RATE, FPS, FRAME_SIZE, MIN_DUR, ASR_MODEL\n\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm import tqdm\n\n# Load the normalized label CSVs you just wrote\nLAB_HC = META / \"labels_raw\" / \"hateclipseg_segments.csv\"\nLAB_MM = META / \"labels_raw\" / \"hatemm_spans.csv\"\nLAB_MH = META / \"labels_raw\" / \"multihateclip_en.csv\"\n\nhc_df = pd.read_csv(LAB_HC) if LAB_HC.exists() else pd.DataFrame()\nmm_df = pd.read_csv(LAB_MM) if LAB_MM.exists() else pd.DataFrame()\nmh_df = pd.read_csv(LAB_MH) if LAB_MH.exists() else pd.DataFrame()\n\nprint(\"HateClipSeg rows:\", len(hc_df))\nprint(\"HateMM rows:\", len(mm_df))\nprint(\"MultiHateClip rows:\", len(mh_df))\n\n# ---------- dataset-specific preprocess ----------\n\ndef preprocess_hateclipseg(df: pd.DataFrame) -> pd.DataFrame:\n    rec=[]; asr = ASR(ASR_MODEL) if RUN_ASR else None\n    for r in tqdm(df.to_dict(orient=\"records\"), desc=\"HateClipSeg\"):\n        in_mp4 = Path(r[\"video_path\"])\n        start, end = float(r[\"start\"]), float(r[\"end\"])\n        dur = max(0.0, end - start)\n        if dur < MIN_DUR: continue\n\n        seg_id = str(r[\"seg_id\"])\n        out_seg = PROC / \"segments\" / \"hateclipseg\" / f\"{seg_id}.mp4\"\n        src = out_seg\n        if CUT_SEGMENTS:\n            if not out_seg.exists():\n                ffmpeg_cut_segment(in_mp4, start, dur, out_seg)\n        else:\n            src = in_mp4\n\n        audio = PROC / \"audio\" / \"hateclipseg\" / f\"{seg_id}.wav\"\n        frames_dir = PROC / \"frames\" / \"hateclipseg\" / seg_id\n        mel = PROC / \"mels\" / \"hateclipseg\" / f\"{seg_id}.npy\"\n        txt = PROC / \"text\" / \"hateclipseg\" / f\"{seg_id}.txt\"\n\n        if EXTRACT_AUDIO and not audio.exists(): ffmpeg_extract_audio(src, audio, SAMPLE_RATE)\n        if EXTRACT_FRAMES and not frames_dir.exists(): ffmpeg_extract_frames(src, frames_dir, FPS, FRAME_SIZE)\n        if EXTRACT_MELS and not mel.exists(): save_mel(audio, mel, SAMPLE_RATE)\n        if RUN_ASR and not txt.exists():\n            txt.parent.mkdir(parents=True, exist_ok=True)\n            txt.write_text(asr.transcribe(audio), encoding=\"utf-8\")\n\n        rec.append({\n            \"dataset\":\"HateClipSeg\",\"sample_id\":seg_id,\n            \"video_path\":str(in_mp4),\"segment_path\":str(out_seg),\n            \"audio_path\":str(audio),\"frames_dir\":str(frames_dir),\n            \"mel_path\":str(mel),\"text_path\":str(txt),\n            \"start\":start,\"end\":end,\"duration\":dur,\n            \"label_multiclass\": r.get(\"label_multiclass\", r.get(\"label\", \"\")),\n            \"label_bin\": 0 if str(r.get(\"label\",\"\")).strip().lower()==\"normal\" else 1,\n            \"target_group\": r.get(\"target_group\",\"\")\n        })\n    return pd.DataFrame.from_records(rec)\n\ndef preprocess_hatemm(df: pd.DataFrame) -> pd.DataFrame:\n    rec=[]; asr = ASR(ASR_MODEL) if RUN_ASR else None\n    for r in tqdm(df.to_dict(orient=\"records\"), desc=\"HateMM\"):\n        in_mp4 = Path(r[\"video_path\"])\n        start, end = float(r[\"start\"]), float(r[\"end\"])\n        full = (end > 9e8)  # sentinel for \"full video\"\n        if not full:\n            dur = max(0.0, end - start)\n            if dur < MIN_DUR: continue\n\n        seg_id = str(r[\"seg_id\"])\n        out_seg = PROC / \"segments\" / \"hatemm\" / f\"{seg_id}.mp4\"\n        if CUT_SEGMENTS:\n            if full:\n                if not out_seg.exists():\n                    run([\"ffmpeg\",\"-hide_banner\",\"-loglevel\",\"error\",\"-i\",str(in_mp4),\n                         \"-c:v\",\"libx264\",\"-preset\",\"veryfast\",\"-crf\",\"23\",\"-c:a\",\"aac\",\"-y\",str(out_seg)])\n            else:\n                if not out_seg.exists(): ffmpeg_cut_segment(in_mp4, start, dur, out_seg)\n        src = out_seg if CUT_SEGMENTS else in_mp4\n\n        audio = PROC / \"audio\" / \"hatemm\" / f\"{seg_id}.wav\"\n        frames_dir = PROC / \"frames\" / \"hatemm\" / seg_id\n        mel = PROC / \"mels\" / \"hatemm\" / f\"{seg_id}.npy\"\n        txt = PROC / \"text\" / \"hatemm\" / f\"{seg_id}.txt\"\n\n        if EXTRACT_AUDIO and not audio.exists(): ffmpeg_extract_audio(src, audio, SAMPLE_RATE)\n        if EXTRACT_FRAMES and not frames_dir.exists(): ffmpeg_extract_frames(src, frames_dir, FPS, FRAME_SIZE)\n        if EXTRACT_MELS and not mel.exists(): save_mel(audio, mel, SAMPLE_RATE)\n        if RUN_ASR and not txt.exists():\n            txt.parent.mkdir(parents=True, exist_ok=True)\n            txt.write_text(asr.transcribe(audio), encoding=\"utf-8\")\n\n        rec.append({\n            \"dataset\":\"HateMM\",\"sample_id\":seg_id,\n            \"video_path\":str(in_mp4),\"segment_path\":str(out_seg),\n            \"audio_path\":str(audio),\"frames_dir\":str(frames_dir),\n            \"mel_path\":str(mel),\"text_path\":str(txt),\n            \"start\":start,\"end\":(None if full else end),\n            \"duration\":(None if full else dur),\n            \"label_bin\": 1 if str(r.get(\"label\",\"\")).strip().lower() in [\"hate\",\"hateful\",\"offensive\"] else 0,\n            \"target\": r.get(\"target\",\"\")\n        })\n    return pd.DataFrame.from_records(rec)\n\ndef preprocess_multihateclip(df: pd.DataFrame) -> pd.DataFrame:\n    rec=[]; asr = ASR(ASR_MODEL) if RUN_ASR else None\n    for r in tqdm(df.to_dict(orient=\"records\"), desc=\"MultiHateClip\"):\n        vid = str(r[\"video_id\"]); in_mp4 = Path(r[\"video_path\"])\n        stem = Path(vid).stem\n\n        audio = PROC / \"audio\" / \"multihateclip_en\" / f\"{stem}.wav\"\n        frames_dir = PROC / \"frames\" / \"multihateclip_en\" / stem\n        mel = PROC / \"mels\" / \"multihateclip_en\" / f\"{stem}.npy\"\n        txt = PROC / \"text\" / \"multihateclip_en\" / f\"{stem}.txt\"\n\n        if EXTRACT_AUDIO and not audio.exists(): ffmpeg_extract_audio(in_mp4, audio, SAMPLE_RATE)\n        if EXTRACT_FRAMES and not frames_dir.exists(): ffmpeg_extract_frames(in_mp4, frames_dir, FPS, FRAME_SIZE)\n        if EXTRACT_MELS and not mel.exists(): save_mel(audio, mel, SAMPLE_RATE)\n        if RUN_ASR and not txt.exists():\n            txt.parent.mkdir(parents=True, exist_ok=True)\n            txt.write_text(asr.transcribe(audio), encoding=\"utf-8\")\n\n        rec.append({\n            \"dataset\":\"MultiHateClip\",\"sample_id\":stem,\n            \"video_path\":str(in_mp4),\"segment_path\":\"\",\n            \"audio_path\":str(audio),\"frames_dir\":str(frames_dir),\n            \"mel_path\":str(mel),\"text_path\":str(txt),\n            \"start\":0.0,\"end\":None,\"duration\":None,\n            \"label_bin\": 0 if str(r[\"label\"]).strip().lower()==\"normal\" else 1,\n            \"split\": r.get(\"split\",\"\")\n        })\n    return pd.DataFrame.from_records(rec)\n\ndfs=[]\nif len(hc_df): dfs.append(preprocess_hateclipseg(hc_df))\nif len(mm_df): dfs.append(preprocess_hatemm(mm_df))\nif len(mh_df): dfs.append(preprocess_multihateclip(mh_df))\n\nmeta = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\nprint(\"Total processed samples:\", len(meta))\ndisplay(meta.head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:35:33.375194Z","iopub.execute_input":"2025-09-14T03:35:33.375758Z","iopub.status.idle":"2025-09-14T03:35:33.932242Z","shell.execute_reply.started":"2025-09-14T03:35:33.375716Z","shell.execute_reply":"2025-09-14T03:35:33.931359Z"}},"outputs":[{"name":"stdout","text":"HateClipSeg rows: 2\nHateMM rows: 1083\nMultiHateClip rows: 1004\n","output_type":"stream"},{"name":"stderr","text":"HateClipSeg:   0%|          | 0/2 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1592353610.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhc_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_hateclipseg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhc_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_hatemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmm_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmh_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_multihateclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmh_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1592353610.py\u001b[0m in \u001b[0;36mpreprocess_hateclipseg\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mrec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0masr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mASR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mASR_MODEL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mRUN_ASR\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"records\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HateClipSeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0min_mp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"video_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindowsPath\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mPosixPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             raise NotImplementedError(\"cannot instantiate %r on your system\"\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# right flavour.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mparts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                     \u001b[0;31m# Force-cast str subclasses to str (issue #21127)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not float"],"ename":"TypeError","evalue":"expected str, bytes or os.PathLike object, not float","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"# %% [markdown]\n# ## Save unified metadata parquet\nmeta_path = META / \"metadata_master.parquet\"\nmeta.to_parquet(meta_path, index=False)\nprint(\"Saved:\", meta_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:35:42.000590Z","iopub.execute_input":"2025-09-14T03:35:42.000887Z","iopub.status.idle":"2025-09-14T03:35:42.011412Z","shell.execute_reply.started":"2025-09-14T03:35:42.000864Z","shell.execute_reply":"2025-09-14T03:35:42.010473Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1385912813.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ## Save unified metadata parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmeta_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETA\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"metadata_master.parquet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'meta' is not defined"],"ename":"NameError","evalue":"name 'meta' is not defined","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"# %% [markdown]\n# ## Create stratified splits for items without an explicit split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\n\nif \"split\" not in meta.columns:\n    meta[\"split\"] = \"\"\n\nneeds = meta[\"split\"].isin([\"\",\"unsplit\",\"nan\",np.nan])\nto_split = meta[needs & meta[\"label_bin\"].notna()].copy()\n\nif len(to_split):\n    y = to_split[\"label_bin\"].astype(int)\n    sss_test = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n    tr_idx, te_idx = next(sss_test.split(to_split, y))\n    idx = to_split.index\n    meta.loc[idx[te_idx], \"split\"] = \"test\"\n\n    remain = to_split.loc[idx[tr_idx]]\n    y2 = remain[\"label_bin\"].astype(int)\n    sss_val = StratifiedShuffleSplit(n_splits=1, test_size=0.111, random_state=42)  # ~10% total\n    tr2, va2 = next(sss_val.split(remain, y2))\n    meta.loc[remain.index[va2], \"split\"] = \"val\"\n    meta.loc[remain.index[tr2], \"split\"] = \"train\"\n\nprint(meta[\"split\"].value_counts(dropna=False))\nmeta.to_parquet(meta_path, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:35:46.273463Z","iopub.execute_input":"2025-09-14T03:35:46.274085Z","iopub.status.idle":"2025-09-14T03:35:47.386676Z","shell.execute_reply.started":"2025-09-14T03:35:46.274058Z","shell.execute_reply":"2025-09-14T03:35:47.385769Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1375068559.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m\"split\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'meta' is not defined"],"ename":"NameError","evalue":"name 'meta' is not defined","output_type":"error"}],"execution_count":27},{"cell_type":"code","source":"# %% [markdown]\n# ## Sanity checks: counts & quick peek\nprint(meta.groupby([\"dataset\",\"split\",\"label_bin\"]).size().reset_index(name=\"count\").head(20))\n\n# Peek one sample per dataset (paths exist?)\nfor ds in [\"HateClipSeg\",\"HateMM\",\"MultiHateClip\"]:\n    sub = meta[meta[\"dataset\"]==ds].head(1)\n    if len(sub):\n        row = sub.iloc[0].to_dict()\n        print(f\"\\n[{ds}] sample_id={row['sample_id']}\")\n        print(\"segment_path:\", row.get(\"segment_path\"))\n        print(\"audio_path  :\", row.get(\"audio_path\"))\n        print(\"frames_dir  :\", row.get(\"frames_dir\"))\n        print(\"text_path   :\", row.get(\"text_path\"))\n        # show transcript head if available\n        tp = row.get(\"text_path\")\n        if tp and Path(tp).exists():\n            print(\"Transcript:\", Path(tp).read_text(encoding=\"utf-8\")[:200], \"...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:35:50.464409Z","iopub.execute_input":"2025-09-14T03:35:50.464913Z","iopub.status.idle":"2025-09-14T03:35:50.478999Z","shell.execute_reply.started":"2025-09-14T03:35:50.464888Z","shell.execute_reply":"2025-09-14T03:35:50.477997Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1944349455.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %% [markdown]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ## Sanity checks: counts & quick peek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label_bin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Peek one sample per dataset (paths exist?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'meta' is not defined"],"ename":"NameError","evalue":"name 'meta' is not defined","output_type":"error"}],"execution_count":28},{"cell_type":"code","source":"# %% [markdown]\n# ## Text-only baseline (BERT) ‚Äî smoke test for the pipeline\nimport torch, numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizerFast, BertForSequenceClassification, get_linear_schedule_with_warmup\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\nfrom pathlib import Path\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntok = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n\ndef subset(df, split):\n    sub = df[df[\"split\"]==split].copy()\n    sub = sub[~sub[\"text_path\"].isna()]\n    return sub\n\ntrain_df = subset(meta, \"train\")\nval_df   = subset(meta, \"val\")\ntest_df  = subset(meta, \"test\")\nprint(\"Sizes:\", len(train_df), len(val_df), len(test_df))\n\nclass TextDS(Dataset):\n    def __init__(self, df, tok, max_len=256):\n        self.df = df.reset_index(drop=True); self.tok=tok; self.max_len=max_len\n        self.txts = []\n        for p in self.df[\"text_path\"].fillna(\"\"):\n            try: self.txts.append(Path(p).read_text(encoding=\"utf-8\"))\n            except: self.txts.append(\"\")\n        self.labels = self.df[\"label_bin\"].astype(int).tolist()\n    def __len__(self): return len(self.df)\n    def __getitem__(self, i):\n        enc = self.tok(self.txts[i], truncation=True, padding=\"max_length\",\n                       max_length=self.max_len, return_tensors=\"pt\")\n        item = {k:v.squeeze(0) for k,v in enc.items()}\n        item[\"labels\"] = torch.tensor(self.labels[i]).long()\n        return item\n\ntrain_loader = DataLoader(TextDS(train_df, tok), batch_size=8, shuffle=True, num_workers=2)\nval_loader   = DataLoader(TextDS(val_df, tok),   batch_size=8, shuffle=False, num_workers=2)\ntest_loader  = DataLoader(TextDS(test_df, tok),  batch_size=8, shuffle=False, num_workers=2)\n\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\nopt = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\nepochs = 2\nsteps = max(1, epochs*len(train_loader))\nsched = get_linear_schedule_with_warmup(opt, int(0.1*steps), steps)\n\ndef eval_loader(loader):\n    model.eval(); preds=[]; gts=[]\n    with torch.no_grad():\n        for batch in loader:\n            batch = {k:v.to(device) for k,v in batch.items()}\n            out = model(**batch)\n            p = out.logits.argmax(-1).detach().cpu().numpy()\n            y = batch[\"labels\"].detach().cpu().numpy()\n            preds.append(p); gts.append(y)\n    import numpy as np\n    preds=np.concatenate(preds) if preds else np.array([])\n    gts=np.concatenate(gts) if gts else np.array([])\n    if len(gts)==0:\n        return {\"acc\":None,\"prec\":None,\"rec\":None,\"f1\":None,\"f1_macro\":None}\n    acc = accuracy_score(gts,preds)\n    p,r,f,_ = precision_recall_fscore_support(gts,preds,average=\"binary\",zero_division=0)\n    f1m = f1_score(gts,preds,average=\"macro\")\n    return {\"acc\":acc,\"prec\":p,\"rec\":r,\"f1\":f,\"f1_macro\":f1m}\n\nfor ep in range(1, epochs+1):\n    model.train()\n    for batch in tqdm(train_loader, desc=f\"Epoch {ep}\"):\n        batch = {k:v.to(device) for k,v in batch.items()}\n        out = model(**batch); out.loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        opt.step(); sched.step(); opt.zero_grad()\n    print(\"Val:\", eval_loader(val_loader))\n\nprint(\"Test:\", eval_loader(test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T03:35:53.122032Z","iopub.execute_input":"2025-09-14T03:35:53.122312Z","iopub.status.idle":"2025-09-14T03:35:55.574338Z","shell.execute_reply.started":"2025-09-14T03:35:53.122291Z","shell.execute_reply":"2025-09-14T03:35:55.573481Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9d5241e2b2349069bdb5126657ea342"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ade4c7b169404a359943d3f004f93541"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"548eae0ef82044909ac07d350b0b8d37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e450fa3001fe44c7bb5239284d46e4ae"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1608220753.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mval_df\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtest_df\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'meta' is not defined"],"ename":"NameError","evalue":"name 'meta' is not defined","output_type":"error"}],"execution_count":29}]}